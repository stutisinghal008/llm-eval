{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c21949",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "BASE_DIR = pathlib.Path.cwd().resolve().parents[1]\n",
    "DATA_DIR = BASE_DIR /\"data\"\n",
    "OUT_DIR = BASE_DIR / \"inference\" / \"outputs\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9cf3f",
   "metadata": {},
   "source": [
    "## Slicing dataset aNd splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"TIGER-Lab/MMLU-Pro\", split=\"test[:1000]\")\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "df = df[[\"question_id\", \"question\", \"options\", \"answer\"]].rename(columns={\"question_id\": \"id\", \"options\": \"choices\"})\n",
    "df.to_csv(DATA_DIR / \"mmlu_pro_1k.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned and saved:\", len(df), \"rows ‚Üí\", DATA_DIR / \"mmlu_pro_1k.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c876811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "calib_df, eval_df = train_test_split(df, test_size=0.85, random_state=42, shuffle=True)\n",
    "calib_df.to_csv(DATA_DIR / \"calibration_split.csv\", index=False)\n",
    "eval_df.to_csv(DATA_DIR / \"evaluation_split.csv\", index=False)\n",
    "\n",
    "print(\"Split complete:\")\n",
    "print(\"Calibration:\", len(calib_df), \"rows\")\n",
    "print(\"Evaluation :\", len(eval_df), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad17ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calibration sample:\")\n",
    "display(calib_df.head(3))\n",
    "\n",
    "print(\"Evaluation sample:\")\n",
    "display(eval_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sim_df = eval_df.copy()\n",
    "rng = np.random.default_rng(42)\n",
    "all_choices = [list(c) for c in sim_df[\"choices\"]]\n",
    "sim_df[\"pred\"] = [rng.choice(choices) for choices in all_choices]\n",
    "sim_df[\"conf\"] = rng.uniform(0.4, 1.0, size=len(sim_df)).round(3)\n",
    "\n",
    "MODEL_NAME = \"simulated_model\"   \n",
    "DATASET_FILENAME = \"mmlu_pro_1k.csv\"\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"{MODEL_NAME}-{DATASET_FILENAME.split('.')[0]}_by_threshold.csv\"\n",
    "sim_df.to_csv(OUTPUT_PATH,index=False)\n",
    "\n",
    "print(\"Simulated predictions created ‚Üí\", OUT_DIR / \"simulated_model_outputs.csv\")\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac643ad",
   "metadata": {},
   "source": [
    "## QWEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e4ca7",
   "metadata": {},
   "source": [
    "### Please run n check this \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install -q transformers accelerate bitsandbytes pandas\n",
    "# # !pip install -q --upgrade transformers accelerate bitsandbytes pandas==2.2.2\n",
    "# # Verify installation\n",
    "# import torch\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import transformers\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import gc\n",
    "\n",
    "# major, minor = map(int, transformers.__version__.split('.')[:2])\n",
    "# if (major, minor) < (4, 37):\n",
    "#     raise ValueError(f\"Transformers {transformers.__version__} too old. Need 4.37+.\")\n",
    "\n",
    "# MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# print(f\"Loading: {MODEL_NAME}\")\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "#     dtype = torch.float16\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     dtype = torch.float32\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     torch_dtype=dtype,\n",
    "#     device_map=None, \n",
    "#     token=HF_TOKEN\n",
    "# ).to(device)\n",
    "\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# print(f\"Model loaded successfully on {device} with dtype={dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6677c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import time\n",
    "# from collections import Counter\n",
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# def extract_letter(text):\n",
    "#     text_clean = text.strip().upper()\n",
    "\n",
    "#     if \"I DON'T KNOW\" in text_clean:\n",
    "#         return \"IDK\"\n",
    "\n",
    "#     m = re.search(r\"\\b([A-D])\\b\", text_clean)\n",
    "#     return m.group(1) if m else None\n",
    "\n",
    "\n",
    "# def qwen_answer_and_conf(prompt, n=6, temperature=0.7):\n",
    "#     votes = []\n",
    "#     for _ in range(n):\n",
    "#         try:\n",
    "#             messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#             formatted_prompt = tokenizer.apply_chat_template(\n",
    "#                 messages, tokenize=False, add_generation_prompt=True\n",
    "#             )\n",
    "\n",
    "#             inputs = tokenizer(\n",
    "#                 formatted_prompt,\n",
    "#                 return_tensors=\"pt\",\n",
    "#                 truncation=True,\n",
    "#                 max_length=512\n",
    "#             ).to(model.device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model.generate(\n",
    "#                     **inputs,\n",
    "#                     max_new_tokens=10,\n",
    "#                     temperature=temperature,\n",
    "#                     do_sample=True if temperature > 0 else False,\n",
    "#                     pad_token_id=tokenizer.pad_token_id,\n",
    "#                     eos_token_id=tokenizer.eos_token_id\n",
    "#                 )\n",
    "\n",
    "#             txt = tokenizer.decode(\n",
    "#                 outputs[0][inputs['input_ids'].shape[1]:],\n",
    "#                 skip_special_tokens=True\n",
    "#             ).strip()\n",
    "\n",
    "#             letter = extract_letter(txt)\n",
    "#             if letter:\n",
    "#                 votes.append(letter)\n",
    "\n",
    "#             del inputs, outputs\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(\"Error:\", e)\n",
    "\n",
    "#         time.sleep(0.1)\n",
    "\n",
    "#     if not votes:\n",
    "#         return \"IDK\", 0.0\n",
    "\n",
    "#     counts = Counter(votes)\n",
    "#     pred = counts.most_common(1)[0][0]\n",
    "#     conf = counts[pred] / len(votes)\n",
    "#     return pred, float(conf)\n",
    "\n",
    "\n",
    "# subset_df = pd.read_csv(\"outputs/week7/mmlu_full_all_thresholds.csv\")\n",
    "# print(f\"Loaded {len(subset_df)} examples from all thresholds\")\n",
    "\n",
    "# qwen_rows = []\n",
    "# total_q = len(subset_df)\n",
    "\n",
    "# for i, row in subset_df.iterrows():\n",
    "#     prompt = row[\"prompt\"]\n",
    "#     t = row[\"threshold\"]\n",
    "\n",
    "#     print(f\"[t={t} | {i+1}/{total_q}] Asking Qwen2.5-1.5B ...\")\n",
    "#     pred, conf = qwen_answer_and_conf(prompt, n=6)\n",
    "\n",
    "#     qwen_rows.append({\n",
    "#         \"id\": row[\"id\"],\n",
    "#         \"threshold\": t,  # <--- include threshold\n",
    "#         \"question\": row[\"question\"],\n",
    "#         \"choices\": row[\"choices\"],\n",
    "#         \"answer\": row[\"answer\"],\n",
    "#         \"predicted_answer\": pred,\n",
    "#         \"confidence\": conf\n",
    "#     })\n",
    "\n",
    "#     if (i + 1) % 5 == 0:\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "# qwen_out = pd.DataFrame(qwen_rows)\n",
    "# qwen_path= OUT_DIR / f\"qwen-mmlu.csv\"\n",
    "# qwen_out.to_csv(qwen_path, index=False)\n",
    "# print(f\"Qwen2.5-1.5B predictions for all thresholds saved ‚Üí {qwen_path}\")\n",
    "# qwen_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b479c",
   "metadata": {},
   "source": [
    "## GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2491be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, time, ast, os\n",
    "from collections import Counter\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "DATASET_NAME = \"mmlu\"\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"gpt-{DATASET_NAME}.csv\"\n",
    "print(\"Saving to:\", OUTPUT_PATH)\n",
    "\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "print(\"Loaded evaluation_split.csv ‚Üí\", len(eval_df), \"rows\")\n",
    "\n",
    "def build_mcq_prompt(row, t):\n",
    "    opts = row[\"choices\"]\n",
    "    if isinstance(opts, str):\n",
    "        try:\n",
    "            opts = ast.literal_eval(opts)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    lines = [f\"Q: {row['question']}\", \"Options:\"]\n",
    "    if isinstance(opts, (list, tuple)):\n",
    "        for i, choice in enumerate(opts):\n",
    "            lines.append(f\"{labels[i]}. {choice}\")\n",
    "    else:\n",
    "        lines.append(str(opts))\n",
    "\n",
    "    lines.append(\n",
    "        f\"\\nAnswer only if you are more than {t} confident. \"\n",
    "        f\"Mistakes incur {t}/(1‚àí{t}) penalty points, correct = +1, IDK = 0. \"\n",
    "        \"If unsure, respond exactly with 'I don't know'.\\n\"\n",
    "        \"Provide ONLY the capital letter (A, B, C, ‚Ä¶) OR 'I don't know'.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def extract_letter(text):\n",
    "    clean = text.strip().upper()\n",
    "    if \"I DON'T KNOW\" in clean:\n",
    "        return \"IDK\"\n",
    "    match = re.search(r\"\\b([A-Z])\\b\", clean)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "def gpt_answer_and_conf(prompt, n=6, temperature=0.7, sleep_s=0.4):\n",
    "    votes = []\n",
    "    for _ in range(n):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "                max_tokens=10\n",
    "            )\n",
    "            txt = resp.choices[0].message.content.strip()\n",
    "            letter = extract_letter(txt)\n",
    "            if letter:\n",
    "                votes.append(letter)\n",
    "        except Exception as e:\n",
    "            print(\"GPT Error:\", e)\n",
    "\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "    if not votes:\n",
    "        return \"IDK\", 0.0\n",
    "\n",
    "    counts = Counter(votes)\n",
    "    pred = counts.most_common(1)[0][0]\n",
    "    conf = counts[pred] / len(votes)\n",
    "    return pred, float(conf)\n",
    "\n",
    "\n",
    "if OUTPUT_PATH.exists():\n",
    "    existing = pd.read_csv(OUTPUT_PATH)\n",
    "    saved_rows = existing.to_dict(\"records\")\n",
    "    done_pairs = set(zip(existing[\"id\"], existing[\"threshold\"]))\n",
    "    print(\"Resuming ‚Äî loaded\", len(saved_rows), \"rows.\")\n",
    "else:\n",
    "    saved_rows = []\n",
    "    done_pairs = set()\n",
    "    print(\"Starting fresh.\")\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "new_since_save = 0\n",
    "total = len(eval_df)\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"\\n=== Threshold t={t} ===\")\n",
    "\n",
    "    for idx, row in eval_df.iterrows():\n",
    "        key = (row[\"id\"], float(t))\n",
    "        if key in done_pairs:\n",
    "            continue\n",
    "\n",
    "        prompt = build_mcq_prompt(row, t)\n",
    "        print(f\"[t={t}] {idx+1}/{total} ‚Üí GPT...\")\n",
    "\n",
    "        pred, conf = gpt_answer_and_conf(prompt)\n",
    "\n",
    "        saved_rows.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"threshold\": t,\n",
    "            \"question\": row[\"question\"],\n",
    "            \"choices\": row[\"choices\"],\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"predicted_answer\": pred,\n",
    "            \"confidence\": conf\n",
    "        })\n",
    "        done_pairs.add(key)\n",
    "        new_since_save += 1\n",
    "\n",
    "        if new_since_save >= SAVE_EVERY:\n",
    "            pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "            print(f\"üíæ Saved {len(saved_rows)} rows.\")\n",
    "            new_since_save = 0\n",
    "\n",
    "\n",
    "pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"saved:\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e97427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "downloads_path = os.path.expanduser(\"~/Downloads\")\n",
    "local_copy_path = os.path.join(downloads_path, os.path.basename(OUTPUT_PATH))\n",
    "\n",
    "shutil.copy(OUTPUT_PATH, local_copy_path)\n",
    "\n",
    "print(\"copied to Downloads:\", local_copy_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1f06f",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, time, ast, os\n",
    "from collections import Counter\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "MODEL_NAME = \"gemini-\"\n",
    "DATASET_NAME = \"mmlu\"\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"{MODEL_NAME}-{DATASET_NAME}.csv\"\n",
    "print(\"Saving to:\", OUTPUT_PATH)\n",
    "\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "print(\"Loaded evaluation_split.csv ‚Üí\", len(eval_df), \"rows\")\n",
    "\n",
    "def build_mcq_prompt(row, t):\n",
    "    opts = row[\"choices\"]\n",
    "\n",
    "    if isinstance(opts, str):\n",
    "        try:\n",
    "            opts = ast.literal_eval(opts)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    lines = [f\"Q: {row['question']}\", \"Options:\"]\n",
    "\n",
    "    if isinstance(opts, (list, tuple)):\n",
    "        for i, choice in enumerate(opts):\n",
    "            lines.append(f\"{labels[i]}. {choice}\")\n",
    "    else:\n",
    "        lines.append(str(opts))\n",
    "\n",
    "    lines.append(\n",
    "        f\"\\nAnswer only if you are more than {t} confident. \"\n",
    "        f\"Mistakes incur {t}/(1‚àí{t}) penalty points, correct = +1, IDK = 0. \"\n",
    "        \"If unsure, respond exactly with 'I don't know'.\\n\"\n",
    "        \"Provide ONLY the capital letter (A, B, C, ‚Ä¶) OR 'I don't know'.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def extract_gemini_text(resp):\n",
    "    try:\n",
    "        return resp.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return resp.candidates[0].content.parts[0].text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_letter(text):\n",
    "    clean = text.strip().upper()\n",
    "    if \"I DON'T KNOW\" in clean:\n",
    "        return \"IDK\"\n",
    "    m = re.search(r\"\\b([A-Z])\\b\", clean)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "gemini_model = genai.GenerativeModel(MODEL_NAME)\n",
    "\n",
    "\n",
    "def gemini_answer_and_conf(prompt, n=6, temperature=0.7, base_sleep=1.5):\n",
    "    \"\"\"\n",
    "    A safe version with:\n",
    "    - auto-retry on 429 rate limits\n",
    "    - sleeps between calls\n",
    "    - returns predicted letter + confidence\n",
    "    \"\"\"\n",
    "    votes = []\n",
    "    for _ in range(n):\n",
    "        while True:\n",
    "            try:\n",
    "                resp = gemini_model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        temperature=temperature,\n",
    "                        max_output_tokens=10\n",
    "                    )\n",
    "                )\n",
    "                txt = extract_gemini_text(resp).strip()\n",
    "                letter = extract_letter(txt)\n",
    "                if letter:\n",
    "                    votes.append(letter)\n",
    "                time.sleep(base_sleep)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                print(\"Gemini Error:\", err)\n",
    "\n",
    "                if \"429\" in err or \"Quota exceeded\" in err:\n",
    "                    retry_sec = 45\n",
    "                    m = re.search(r\"retry_delay.*?(\\d+)\", err)\n",
    "                    if m:\n",
    "                        retry_sec = int(m.group(1))\n",
    "                    print(f\"Rate limit hit. Sleeping {retry_sec} seconds‚Ä¶\")\n",
    "                    time.sleep(retry_sec)\n",
    "                    continue\n",
    "                print(\"Non-quota error. Sleeping 5 seconds‚Ä¶\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "    if not votes:\n",
    "        return \"IDK\", 0.0\n",
    "    counts = Counter(votes)\n",
    "    pred = counts.most_common(1)[0][0]\n",
    "    conf = counts[pred] / len(votes)\n",
    "    return pred, float(conf)\n",
    "\n",
    "if OUTPUT_PATH.exists():\n",
    "    existing = pd.read_csv(OUTPUT_PATH)\n",
    "    saved_rows = existing.to_dict(\"records\")\n",
    "    done_pairs = set(zip(existing[\"id\"], existing[\"threshold\"]))\n",
    "    print(\"Resuming ‚Äî loaded\", len(saved_rows), \"rows.\")\n",
    "else:\n",
    "    saved_rows = []\n",
    "    done_pairs = set()\n",
    "    print(\"Starting fresh.\")\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "new_since_save = 0\n",
    "total = len(eval_df)\n",
    "\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"\\n=== Threshold t={t} ===\")\n",
    "    for idx, row in eval_df.iterrows():\n",
    "        key = (row[\"id\"], float(t))\n",
    "        if key in done_pairs:\n",
    "            continue\n",
    "        prompt = build_mcq_prompt(row, t)\n",
    "        print(f\"[t={t}] {idx+1}/{total} ‚Üí Gemini...\")\n",
    "        pred, conf = gemini_answer_and_conf(prompt)\n",
    "        saved_rows.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"threshold\": t,\n",
    "            \"question\": row[\"question\"],\n",
    "            \"choices\": row[\"choices\"],\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"predicted_answer\": pred,\n",
    "            \"confidence\": conf\n",
    "        })\n",
    "        done_pairs.add(key)\n",
    "        new_since_save += 1\n",
    "        if new_since_save >= SAVE_EVERY:\n",
    "            pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "            print(f\"üíæ Saved {len(saved_rows)} rows.\")\n",
    "            new_since_save = 0\n",
    "pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"saved:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "MODEL_NAME = \"gemini\"\n",
    "DATASET_NAME = \"mmlu\"\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"{MODEL_NAME}-{DATASET_NAME}.csv\"\n",
    "print(\"Checking file:\", OUTPUT_PATH)\n",
    "\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "res_df = pd.read_csv(OUTPUT_PATH)\n",
    "\n",
    "print(\"eval_df rows:\", len(eval_df))\n",
    "print(\"result rows:\", len(res_df))\n",
    "\n",
    "res_df[\"threshold\"] = res_df[\"threshold\"].astype(float)\n",
    "dups = (\n",
    "    res_df.groupby([\"id\", \"threshold\"])\n",
    "          .size()\n",
    "          .reset_index(name=\"count\")\n",
    "          .query(\"count > 1\")\n",
    ")\n",
    "print(\"Duplicate (id, threshold) rows:\", len(dups))\n",
    "\n",
    "eval_ids = set(eval_df[\"id\"])\n",
    "res_ids = set(res_df[\"id\"])\n",
    "\n",
    "missing_ids = eval_ids - res_ids\n",
    "extra_ids = res_ids - eval_ids\n",
    "\n",
    "print(\"Missing IDs:\", len(missing_ids))\n",
    "print(\"Extra IDs:\", len(extra_ids))\n",
    "\n",
    "missing_pairs = []\n",
    "extra_pairs = []\n",
    "\n",
    "for qid in eval_ids:\n",
    "    present = set(res_df.loc[res_df[\"id\"] == qid, \"threshold\"])\n",
    "    for t in THRESHOLDS:\n",
    "        if t not in present:\n",
    "            missing_pairs.append((qid, t))\n",
    "    for t in present:\n",
    "        if t not in THRESHOLDS:\n",
    "            extra_pairs.append((qid, t))\n",
    "\n",
    "print(\"Missing (id, threshold) combos:\", len(missing_pairs))\n",
    "print(\"Extra (id, threshold) combos:\", len(extra_pairs))\n",
    "\n",
    "valid_letters = set(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "valid_answers = valid_letters | {\"IDK\"}\n",
    "\n",
    "invalid_pred = res_df[~res_df[\"predicted_answer\"].astype(str).isin(valid_answers)]\n",
    "print(\"Invalid predicted_answer rows:\", len(invalid_pred))\n",
    "\n",
    "invalid_conf = res_df[\n",
    "    (res_df[\"confidence\"].isna()) |\n",
    "    (res_df[\"confidence\"] < 0) |\n",
    "    (res_df[\"confidence\"] > 1)\n",
    "]\n",
    "print(\"Invalid confidence rows:\", len(invalid_conf))\n",
    "\n",
    "if (\n",
    "    len(dups) == 0 and\n",
    "    len(missing_ids) == 0 and\n",
    "    len(extra_ids) == 0 and\n",
    "    len(missing_pairs) == 0 and\n",
    "    len(extra_pairs) == 0 and\n",
    "    len(invalid_pred) == 0 and\n",
    "    len(invalid_conf) == 0\n",
    "):\n",
    "    print(\"\\nAll sanity checks passed!\")\n",
    "else:\n",
    "    print(\"\\nIssues detected ‚Äî see counts above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2036a0",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, os\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Loaded ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdad693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "if HF_TOKEN is None:\n",
    "    raise ValueError(\"HF_TOKEN missing in .env\")\n",
    "\n",
    "# BASE_DIR = Path.cwd()\n",
    "# DATA_DIR = BASE_DIR / \"data\"\n",
    "# OUT_DIR = BASE_DIR / \"outputs\"\n",
    "# OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR.parent.parent / \"data\"\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16 \n",
    "\n",
    "print(\"Device:\", DEVICE, \"| dtype:\", DTYPE)\n",
    "\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "print(\"Loading model (bf16 on MPS, device_map='auto')...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=HF_TOKEN,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\"      \n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "print(\"Loaded:\", len(eval_df), \"rows\")\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "SAVE_EVERY = 10\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"{DATASET_NAME}-Mistral-7B-Instruct-v0.3_by_threshold.csv\"\n",
    "\n",
    "\n",
    "def build_mcq_prompt(row, t):\n",
    "    opts = row[\"choices\"]\n",
    "    if isinstance(opts, str):\n",
    "        try: opts = ast.literal_eval(opts)\n",
    "        except: pass\n",
    "\n",
    "    labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    text = [f\"Q: {row['question']}\", \"Options:\"]\n",
    "    for i, ch in enumerate(opts):\n",
    "        text.append(f\"{labels[i]}. {ch}\")\n",
    "\n",
    "    text.append(\n",
    "        f\"\\nOnly answer if >{t} confident. Wrong = penalty {t}/(1‚àí{t}), correct=+1, IDK=0.\\n\"\n",
    "        \"If unsure respond EXACTLY: 'I don't know'.\\n\"\n",
    "        \"Return ONLY a letter (A, B, C, ‚Ä¶) OR 'I don't know'.\"\n",
    "    )\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def extract_letter(text):\n",
    "    text = text.strip().upper()\n",
    "    if \"I DON'T KNOW\" in text:\n",
    "        return \"IDK\"\n",
    "    m = re.search(r\"\\b([A-Z])\\b\", text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def model_answer_and_conf(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[:, -1, :]   # only final token\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    pred_id = torch.argmax(logits, dim=-1).item()\n",
    "    pred_text = tokenizer.decode(pred_id)\n",
    "    letter = extract_letter(pred_text)\n",
    "\n",
    "    if letter and letter != \"IDK\":\n",
    "        tid = tokenizer(letter, add_special_tokens=False).input_ids[0]\n",
    "        confidence = probs[0, tid].item()\n",
    "    else:\n",
    "        confidence = 0.0\n",
    "\n",
    "    return letter if letter else \"IDK\", confidence\n",
    "\n",
    "\n",
    "if OUTPUT_PATH.exists():\n",
    "    old = pd.read_csv(OUTPUT_PATH)\n",
    "    saved_rows = old.to_dict(\"records\")\n",
    "    done = set(zip(old[\"id\"], old[\"threshold\"]))\n",
    "    print(\"Resuming from:\", len(old))\n",
    "else:\n",
    "    saved_rows = []\n",
    "    done = set()\n",
    "    print(\"Starting fresh\")\n",
    "\n",
    "save_counter = 0\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"\\n=== t = {t} ===\")\n",
    "\n",
    "    for idx, row in eval_df.iterrows():\n",
    "\n",
    "        key = (row[\"id\"], t)\n",
    "        if key in done:\n",
    "            continue\n",
    "\n",
    "        prompt = build_mcq_prompt(row, t)\n",
    "        pred, conf = model_answer_and_conf(prompt)\n",
    "\n",
    "        final_pred = pred if conf >= t else \"IDK\"\n",
    "\n",
    "        saved_rows.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"threshold\": t,\n",
    "            \"question\": row[\"question\"], \n",
    "            \"choices\": row[\"choices\"],\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"raw_prediction\": pred,\n",
    "            \"confidence\": conf,\n",
    "            \"thresholded_prediction\": final_pred\n",
    "        })\n",
    "\n",
    "        done.add(key)\n",
    "        save_counter += 1\n",
    "\n",
    "        if save_counter >= SAVE_EVERY:\n",
    "            pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "            print(\"Saved\", len(saved_rows))\n",
    "            save_counter = 0\n",
    "\n",
    "pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"\\nDONE ‚Üí\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b47c74",
   "metadata": {},
   "source": [
    "## llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, os\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"\\nLoading model (bf16 on MPS, device_map='auto')...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"Loaded ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e24570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "if HF_TOKEN is None:\n",
    "    raise ValueError(\"HF_TOKEN missing in .env\")\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR.parent.parent / \"data\"\n",
    "OUT_DIR = BASE_DIR.parent.parent / \"outputs\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16\n",
    "\n",
    "print(\"Device:\", DEVICE, \"| dtype:\", DTYPE)\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=HF_TOKEN,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"Loading model (bf16 on MPS, device_map='auto')...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=HF_TOKEN,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "print(\"Loaded:\", len(eval_df), \"rows\")\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "SAVE_EVERY = 10\n",
    "\n",
    "OUTPUT_PATH = OUT_DIR / f\"llama-mmlu.csv\"\n",
    "\n",
    "def build_mcq_prompt(row, t):\n",
    "    opts = row[\"choices\"]\n",
    "    if isinstance(opts, str):\n",
    "        try: opts = ast.literal_eval(opts)\n",
    "        except: pass\n",
    "\n",
    "    labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    text = [f\"Q: {row['question']}\", \"Options:\"]\n",
    "    for i, ch in enumerate(opts):\n",
    "        text.append(f\"{labels[i]}. {ch}\")\n",
    "\n",
    "    text.append(\n",
    "        f\"\\nOnly answer if >{t} confident. Wrong = penalty {t}/(1‚àí{t}), correct=+1, IDK=0.\\n\"\n",
    "        \"If unsure respond EXACTLY: 'I don't know'.\\n\"\n",
    "        \"Return ONLY a letter (A, B, C, ‚Ä¶) OR 'I don't know'.\"\n",
    "    )\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "\n",
    "def extract_letter(text):\n",
    "    text = text.strip().upper()\n",
    "    if \"I DON'T KNOW\" in text:\n",
    "        return \"IDK\"\n",
    "    m = re.search(r\"\\b([A-Z])\\b\", text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def model_answer_and_conf(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[:, -1, :]   # only final token\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    pred_id = torch.argmax(logits, dim=-1).item()\n",
    "    pred_text = tokenizer.decode(pred_id)\n",
    "    letter = extract_letter(pred_text)\n",
    "\n",
    "    if letter and letter != \"IDK\":\n",
    "        tid = tokenizer(letter, add_special_tokens=False).input_ids[0]\n",
    "        confidence = probs[0, tid].item()\n",
    "    else:\n",
    "        confidence = 0.0\n",
    "\n",
    "    return letter if letter else \"IDK\", confidence\n",
    "\n",
    "\n",
    "if OUTPUT_PATH.exists():\n",
    "    old = pd.read_csv(OUTPUT_PATH)\n",
    "    saved_rows = old.to_dict(\"records\")\n",
    "    done = set(zip(old[\"id\"], old[\"threshold\"]))\n",
    "    print(\"Resuming from:\", len(old))\n",
    "else:\n",
    "    saved_rows = []\n",
    "    done = set()\n",
    "    print(\"Starting fresh\")\n",
    "\n",
    "save_counter = 0\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"\\n=== t = {t} ===\")\n",
    "\n",
    "    for idx, row in eval_df.iterrows():\n",
    "\n",
    "        key = (row[\"id\"], t)\n",
    "        if key in done:\n",
    "            continue\n",
    "\n",
    "        prompt = build_mcq_prompt(row, t)\n",
    "        pred, conf = model_answer_and_conf(prompt)\n",
    "\n",
    "        final_pred = pred if conf >= t else \"IDK\"\n",
    "\n",
    "        saved_rows.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"threshold\": t,\n",
    "            \"question\": row[\"question\"], \n",
    "            \"choices\": row[\"choices\"],\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"raw_prediction\": pred,\n",
    "            \"confidence\": conf,\n",
    "            \"thresholded_prediction\": final_pred\n",
    "        })\n",
    "\n",
    "        done.add(key)\n",
    "        save_counter += 1\n",
    "\n",
    "        if save_counter >= SAVE_EVERY:\n",
    "            pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "            print(\"Saved\", len(saved_rows))\n",
    "            save_counter = 0\n",
    "\n",
    "pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"\\nDONE ‚Üí\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948758c6",
   "metadata": {},
   "source": [
    "## Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /Users/stutisinghal/Documents/fall25/NLP/final/final_branch/cloned_final/llm-eval/inference/outputs/claude-mmlu.csv\n",
      "Loaded evaluation_split.csv ‚Üí 850 rows\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, time, ast, os\n",
    "from collections import Counter\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "THRESHOLDS = [0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "MODEL_NAME = \"claude\"\n",
    "DATASET_NAME = \"mmlu\"\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = OUT_DIR / f\"{MODEL_NAME}-{DATASET_NAME}.csv\"\n",
    "print(\"Saving to:\", OUTPUT_PATH)\n",
    "\n",
    "# Load evaluation split\n",
    "eval_df = pd.read_csv(DATA_DIR / \"evaluation_split.csv\")\n",
    "print(\"Loaded evaluation_split.csv ‚Üí\", len(eval_df), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17b075a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mcq_prompt(row, t):\n",
    "    opts = row[\"choices\"]\n",
    "\n",
    "    if isinstance(opts, str):\n",
    "        try:\n",
    "            opts = ast.literal_eval(opts)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    lines = [f\"Q: {row['question']}\", \"Options:\"]\n",
    "\n",
    "    if isinstance(opts, (list, tuple)):\n",
    "        for i, choice in enumerate(opts):\n",
    "            lines.append(f\"{labels[i]}. {choice}\")\n",
    "    else:\n",
    "        lines.append(str(opts))\n",
    "\n",
    "    lines.append(\n",
    "        f\"\\nAnswer only if you are more than {t} confident. \"\n",
    "        f\"Mistakes incur {t}/(1‚àí{t}) penalty points, correct = +1, IDK = 0. \"\n",
    "        \"If unsure, respond exactly with 'I don't know'.\\n\"\n",
    "        \"Provide ONLY the capital letter (A, B, C, ‚Ä¶) OR 'I don't know'.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18082120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_claude_text(resp):\n",
    "    try:\n",
    "        return resp.content[0].text\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22b08f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_letter(text):\n",
    "    clean = text.strip().upper()\n",
    "    if \"I DON'T KNOW\" in clean:\n",
    "        return \"IDK\"\n",
    "    m = re.search(r\"\\b([A-Z])\\b\", clean)\n",
    "    return m.group(1) if m else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "425697a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_answer_and_conf(prompt, n=6, temperature=0.7, base_sleep=1.2):\n",
    "    votes = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        while True:\n",
    "            try:\n",
    "                resp = client.messages.create(\n",
    "                    model=\"claude-haiku-4-5\",\n",
    "                    max_tokens=20,\n",
    "                    temperature=temperature,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                txt = extract_claude_text(resp).strip()\n",
    "                letter = extract_letter(txt)\n",
    "                if letter:\n",
    "                    votes.append(letter)\n",
    "\n",
    "                time.sleep(base_sleep)\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                print(\"Claude Error:\", err)\n",
    "\n",
    "                # Rate limits\n",
    "                if \"rate_limit\" in err or \"429\" in err:\n",
    "                    print(\"üîÅ Rate limit ‚Äî sleeping 30s‚Ä¶\")\n",
    "                    time.sleep(30)\n",
    "                    continue\n",
    "\n",
    "                # Generic temporary errors\n",
    "                print(\"‚ö†Ô∏è Non-rate error ‚Äî sleeping 5s‚Ä¶\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "    if not votes:\n",
    "        return \"IDK\", 0.0\n",
    "\n",
    "    counts = Counter(votes)\n",
    "    pred = counts.most_common(1)[0][0]\n",
    "    conf = counts[pred] / len(votes)\n",
    "    return pred, float(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b3b76186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming ‚Äî loaded 2310 rows.\n"
     ]
    }
   ],
   "source": [
    "if OUTPUT_PATH.exists():\n",
    "    existing = pd.read_csv(OUTPUT_PATH)\n",
    "    saved_rows = existing.to_dict(\"records\")\n",
    "    done_pairs = set(zip(existing[\"id\"], existing[\"threshold\"]))\n",
    "    print(\"Resuming ‚Äî loaded\", len(saved_rows), \"rows.\")\n",
    "else:\n",
    "    saved_rows = []\n",
    "    done_pairs = set()\n",
    "    print(\"Starting fresh.\")\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "new_since_save = 0\n",
    "total = len(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d76ddd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Threshold t=0.25 ===\n",
      "\n",
      "=== Threshold t=0.5 ===\n",
      "\n",
      "=== Threshold t=0.75 ===\n",
      "[t=0.75] 611/850 ‚Üí Claude...\n",
      "[t=0.75] 612/850 ‚Üí Claude...\n",
      "[t=0.75] 613/850 ‚Üí Claude...\n",
      "[t=0.75] 614/850 ‚Üí Claude...\n",
      "[t=0.75] 615/850 ‚Üí Claude...\n",
      "[t=0.75] 616/850 ‚Üí Claude...\n",
      "[t=0.75] 617/850 ‚Üí Claude...\n",
      "[t=0.75] 618/850 ‚Üí Claude...\n",
      "[t=0.75] 619/850 ‚Üí Claude...\n",
      "[t=0.75] 620/850 ‚Üí Claude...\n",
      "üíæ Saved 2320 rows.\n",
      "[t=0.75] 621/850 ‚Üí Claude...\n",
      "[t=0.75] 622/850 ‚Üí Claude...\n",
      "[t=0.75] 623/850 ‚Üí Claude...\n",
      "[t=0.75] 624/850 ‚Üí Claude...\n",
      "[t=0.75] 625/850 ‚Üí Claude...\n",
      "[t=0.75] 626/850 ‚Üí Claude...\n",
      "[t=0.75] 627/850 ‚Üí Claude...\n",
      "[t=0.75] 628/850 ‚Üí Claude...\n",
      "[t=0.75] 629/850 ‚Üí Claude...\n",
      "[t=0.75] 630/850 ‚Üí Claude...\n",
      "üíæ Saved 2330 rows.\n",
      "[t=0.75] 631/850 ‚Üí Claude...\n",
      "[t=0.75] 632/850 ‚Üí Claude...\n",
      "[t=0.75] 633/850 ‚Üí Claude...\n",
      "[t=0.75] 634/850 ‚Üí Claude...\n",
      "[t=0.75] 635/850 ‚Üí Claude...\n",
      "[t=0.75] 636/850 ‚Üí Claude...\n",
      "[t=0.75] 637/850 ‚Üí Claude...\n",
      "[t=0.75] 638/850 ‚Üí Claude...\n",
      "[t=0.75] 639/850 ‚Üí Claude...\n",
      "[t=0.75] 640/850 ‚Üí Claude...\n",
      "üíæ Saved 2340 rows.\n",
      "[t=0.75] 641/850 ‚Üí Claude...\n",
      "[t=0.75] 642/850 ‚Üí Claude...\n",
      "[t=0.75] 643/850 ‚Üí Claude...\n",
      "[t=0.75] 644/850 ‚Üí Claude...\n",
      "[t=0.75] 645/850 ‚Üí Claude...\n",
      "[t=0.75] 646/850 ‚Üí Claude...\n",
      "[t=0.75] 647/850 ‚Üí Claude...\n",
      "[t=0.75] 648/850 ‚Üí Claude...\n",
      "[t=0.75] 649/850 ‚Üí Claude...\n",
      "[t=0.75] 650/850 ‚Üí Claude...\n",
      "üíæ Saved 2350 rows.\n",
      "[t=0.75] 651/850 ‚Üí Claude...\n",
      "[t=0.75] 652/850 ‚Üí Claude...\n",
      "[t=0.75] 653/850 ‚Üí Claude...\n",
      "[t=0.75] 654/850 ‚Üí Claude...\n",
      "[t=0.75] 655/850 ‚Üí Claude...\n",
      "[t=0.75] 656/850 ‚Üí Claude...\n",
      "[t=0.75] 657/850 ‚Üí Claude...\n",
      "[t=0.75] 658/850 ‚Üí Claude...\n",
      "[t=0.75] 659/850 ‚Üí Claude...\n",
      "[t=0.75] 660/850 ‚Üí Claude...\n",
      "üíæ Saved 2360 rows.\n",
      "[t=0.75] 661/850 ‚Üí Claude...\n",
      "[t=0.75] 662/850 ‚Üí Claude...\n",
      "[t=0.75] 663/850 ‚Üí Claude...\n",
      "[t=0.75] 664/850 ‚Üí Claude...\n",
      "[t=0.75] 665/850 ‚Üí Claude...\n",
      "[t=0.75] 666/850 ‚Üí Claude...\n",
      "[t=0.75] 667/850 ‚Üí Claude...\n",
      "[t=0.75] 668/850 ‚Üí Claude...\n",
      "[t=0.75] 669/850 ‚Üí Claude...\n",
      "[t=0.75] 670/850 ‚Üí Claude...\n",
      "üíæ Saved 2370 rows.\n",
      "[t=0.75] 671/850 ‚Üí Claude...\n",
      "[t=0.75] 672/850 ‚Üí Claude...\n",
      "[t=0.75] 673/850 ‚Üí Claude...\n",
      "[t=0.75] 674/850 ‚Üí Claude...\n",
      "[t=0.75] 675/850 ‚Üí Claude...\n",
      "[t=0.75] 676/850 ‚Üí Claude...\n",
      "[t=0.75] 677/850 ‚Üí Claude...\n",
      "[t=0.75] 678/850 ‚Üí Claude...\n",
      "[t=0.75] 679/850 ‚Üí Claude...\n",
      "[t=0.75] 680/850 ‚Üí Claude...\n",
      "üíæ Saved 2380 rows.\n",
      "[t=0.75] 681/850 ‚Üí Claude...\n",
      "[t=0.75] 682/850 ‚Üí Claude...\n",
      "[t=0.75] 683/850 ‚Üí Claude...\n",
      "[t=0.75] 684/850 ‚Üí Claude...\n",
      "[t=0.75] 685/850 ‚Üí Claude...\n",
      "[t=0.75] 686/850 ‚Üí Claude...\n",
      "[t=0.75] 687/850 ‚Üí Claude...\n",
      "[t=0.75] 688/850 ‚Üí Claude...\n",
      "[t=0.75] 689/850 ‚Üí Claude...\n",
      "[t=0.75] 690/850 ‚Üí Claude...\n",
      "üíæ Saved 2390 rows.\n",
      "[t=0.75] 691/850 ‚Üí Claude...\n",
      "[t=0.75] 692/850 ‚Üí Claude...\n",
      "[t=0.75] 693/850 ‚Üí Claude...\n",
      "[t=0.75] 694/850 ‚Üí Claude...\n",
      "[t=0.75] 695/850 ‚Üí Claude...\n",
      "[t=0.75] 696/850 ‚Üí Claude...\n",
      "[t=0.75] 697/850 ‚Üí Claude...\n",
      "[t=0.75] 698/850 ‚Üí Claude...\n",
      "[t=0.75] 699/850 ‚Üí Claude...\n",
      "[t=0.75] 700/850 ‚Üí Claude...\n",
      "üíæ Saved 2400 rows.\n",
      "[t=0.75] 701/850 ‚Üí Claude...\n",
      "[t=0.75] 702/850 ‚Üí Claude...\n",
      "[t=0.75] 703/850 ‚Üí Claude...\n",
      "[t=0.75] 704/850 ‚Üí Claude...\n",
      "[t=0.75] 705/850 ‚Üí Claude...\n",
      "[t=0.75] 706/850 ‚Üí Claude...\n",
      "[t=0.75] 707/850 ‚Üí Claude...\n",
      "[t=0.75] 708/850 ‚Üí Claude...\n",
      "[t=0.75] 709/850 ‚Üí Claude...\n",
      "[t=0.75] 710/850 ‚Üí Claude...\n",
      "üíæ Saved 2410 rows.\n",
      "[t=0.75] 711/850 ‚Üí Claude...\n",
      "[t=0.75] 712/850 ‚Üí Claude...\n",
      "[t=0.75] 713/850 ‚Üí Claude...\n",
      "[t=0.75] 714/850 ‚Üí Claude...\n",
      "[t=0.75] 715/850 ‚Üí Claude...\n",
      "[t=0.75] 716/850 ‚Üí Claude...\n",
      "[t=0.75] 717/850 ‚Üí Claude...\n",
      "[t=0.75] 718/850 ‚Üí Claude...\n",
      "[t=0.75] 719/850 ‚Üí Claude...\n",
      "[t=0.75] 720/850 ‚Üí Claude...\n",
      "üíæ Saved 2420 rows.\n",
      "[t=0.75] 721/850 ‚Üí Claude...\n",
      "[t=0.75] 722/850 ‚Üí Claude...\n",
      "[t=0.75] 723/850 ‚Üí Claude...\n",
      "[t=0.75] 724/850 ‚Üí Claude...\n",
      "[t=0.75] 725/850 ‚Üí Claude...\n",
      "[t=0.75] 726/850 ‚Üí Claude...\n",
      "[t=0.75] 727/850 ‚Üí Claude...\n",
      "[t=0.75] 728/850 ‚Üí Claude...\n",
      "[t=0.75] 729/850 ‚Üí Claude...\n",
      "[t=0.75] 730/850 ‚Üí Claude...\n",
      "üíæ Saved 2430 rows.\n",
      "[t=0.75] 731/850 ‚Üí Claude...\n",
      "[t=0.75] 732/850 ‚Üí Claude...\n",
      "[t=0.75] 733/850 ‚Üí Claude...\n",
      "[t=0.75] 734/850 ‚Üí Claude...\n",
      "[t=0.75] 735/850 ‚Üí Claude...\n",
      "[t=0.75] 736/850 ‚Üí Claude...\n",
      "[t=0.75] 737/850 ‚Üí Claude...\n",
      "[t=0.75] 738/850 ‚Üí Claude...\n",
      "[t=0.75] 739/850 ‚Üí Claude...\n",
      "[t=0.75] 740/850 ‚Üí Claude...\n",
      "üíæ Saved 2440 rows.\n",
      "[t=0.75] 741/850 ‚Üí Claude...\n",
      "[t=0.75] 742/850 ‚Üí Claude...\n",
      "[t=0.75] 743/850 ‚Üí Claude...\n",
      "[t=0.75] 744/850 ‚Üí Claude...\n",
      "[t=0.75] 745/850 ‚Üí Claude...\n",
      "[t=0.75] 746/850 ‚Üí Claude...\n",
      "[t=0.75] 747/850 ‚Üí Claude...\n",
      "[t=0.75] 748/850 ‚Üí Claude...\n",
      "[t=0.75] 749/850 ‚Üí Claude...\n",
      "[t=0.75] 750/850 ‚Üí Claude...\n",
      "üíæ Saved 2450 rows.\n",
      "[t=0.75] 751/850 ‚Üí Claude...\n",
      "[t=0.75] 752/850 ‚Üí Claude...\n",
      "[t=0.75] 753/850 ‚Üí Claude...\n",
      "[t=0.75] 754/850 ‚Üí Claude...\n",
      "[t=0.75] 755/850 ‚Üí Claude...\n",
      "[t=0.75] 756/850 ‚Üí Claude...\n",
      "[t=0.75] 757/850 ‚Üí Claude...\n",
      "[t=0.75] 758/850 ‚Üí Claude...\n",
      "[t=0.75] 759/850 ‚Üí Claude...\n",
      "[t=0.75] 760/850 ‚Üí Claude...\n",
      "üíæ Saved 2460 rows.\n",
      "[t=0.75] 761/850 ‚Üí Claude...\n",
      "[t=0.75] 762/850 ‚Üí Claude...\n",
      "[t=0.75] 763/850 ‚Üí Claude...\n",
      "[t=0.75] 764/850 ‚Üí Claude...\n",
      "[t=0.75] 765/850 ‚Üí Claude...\n",
      "[t=0.75] 766/850 ‚Üí Claude...\n",
      "[t=0.75] 767/850 ‚Üí Claude...\n",
      "[t=0.75] 768/850 ‚Üí Claude...\n",
      "[t=0.75] 769/850 ‚Üí Claude...\n",
      "[t=0.75] 770/850 ‚Üí Claude...\n",
      "üíæ Saved 2470 rows.\n",
      "[t=0.75] 771/850 ‚Üí Claude...\n",
      "[t=0.75] 772/850 ‚Üí Claude...\n",
      "[t=0.75] 773/850 ‚Üí Claude...\n",
      "[t=0.75] 774/850 ‚Üí Claude...\n",
      "[t=0.75] 775/850 ‚Üí Claude...\n",
      "[t=0.75] 776/850 ‚Üí Claude...\n",
      "[t=0.75] 777/850 ‚Üí Claude...\n",
      "[t=0.75] 778/850 ‚Üí Claude...\n",
      "[t=0.75] 779/850 ‚Üí Claude...\n",
      "[t=0.75] 780/850 ‚Üí Claude...\n",
      "üíæ Saved 2480 rows.\n",
      "[t=0.75] 781/850 ‚Üí Claude...\n",
      "[t=0.75] 782/850 ‚Üí Claude...\n",
      "[t=0.75] 783/850 ‚Üí Claude...\n",
      "[t=0.75] 784/850 ‚Üí Claude...\n",
      "[t=0.75] 785/850 ‚Üí Claude...\n",
      "[t=0.75] 786/850 ‚Üí Claude...\n",
      "[t=0.75] 787/850 ‚Üí Claude...\n",
      "[t=0.75] 788/850 ‚Üí Claude...\n",
      "[t=0.75] 789/850 ‚Üí Claude...\n",
      "[t=0.75] 790/850 ‚Üí Claude...\n",
      "üíæ Saved 2490 rows.\n",
      "[t=0.75] 791/850 ‚Üí Claude...\n",
      "[t=0.75] 792/850 ‚Üí Claude...\n",
      "[t=0.75] 793/850 ‚Üí Claude...\n",
      "[t=0.75] 794/850 ‚Üí Claude...\n",
      "[t=0.75] 795/850 ‚Üí Claude...\n",
      "[t=0.75] 796/850 ‚Üí Claude...\n",
      "[t=0.75] 797/850 ‚Üí Claude...\n",
      "[t=0.75] 798/850 ‚Üí Claude...\n",
      "[t=0.75] 799/850 ‚Üí Claude...\n",
      "[t=0.75] 800/850 ‚Üí Claude...\n",
      "üíæ Saved 2500 rows.\n",
      "[t=0.75] 801/850 ‚Üí Claude...\n",
      "[t=0.75] 802/850 ‚Üí Claude...\n",
      "[t=0.75] 803/850 ‚Üí Claude...\n",
      "[t=0.75] 804/850 ‚Üí Claude...\n",
      "[t=0.75] 805/850 ‚Üí Claude...\n",
      "[t=0.75] 806/850 ‚Üí Claude...\n",
      "[t=0.75] 807/850 ‚Üí Claude...\n",
      "[t=0.75] 808/850 ‚Üí Claude...\n",
      "[t=0.75] 809/850 ‚Üí Claude...\n",
      "[t=0.75] 810/850 ‚Üí Claude...\n",
      "üíæ Saved 2510 rows.\n",
      "[t=0.75] 811/850 ‚Üí Claude...\n",
      "[t=0.75] 812/850 ‚Üí Claude...\n",
      "[t=0.75] 813/850 ‚Üí Claude...\n",
      "[t=0.75] 814/850 ‚Üí Claude...\n",
      "[t=0.75] 815/850 ‚Üí Claude...\n",
      "[t=0.75] 816/850 ‚Üí Claude...\n",
      "[t=0.75] 817/850 ‚Üí Claude...\n",
      "[t=0.75] 818/850 ‚Üí Claude...\n",
      "[t=0.75] 819/850 ‚Üí Claude...\n",
      "[t=0.75] 820/850 ‚Üí Claude...\n",
      "üíæ Saved 2520 rows.\n",
      "[t=0.75] 821/850 ‚Üí Claude...\n",
      "[t=0.75] 822/850 ‚Üí Claude...\n",
      "[t=0.75] 823/850 ‚Üí Claude...\n",
      "[t=0.75] 824/850 ‚Üí Claude...\n",
      "[t=0.75] 825/850 ‚Üí Claude...\n",
      "[t=0.75] 826/850 ‚Üí Claude...\n",
      "[t=0.75] 827/850 ‚Üí Claude...\n",
      "[t=0.75] 828/850 ‚Üí Claude...\n",
      "[t=0.75] 829/850 ‚Üí Claude...\n",
      "[t=0.75] 830/850 ‚Üí Claude...\n",
      "üíæ Saved 2530 rows.\n",
      "[t=0.75] 831/850 ‚Üí Claude...\n",
      "[t=0.75] 832/850 ‚Üí Claude...\n",
      "[t=0.75] 833/850 ‚Üí Claude...\n",
      "[t=0.75] 834/850 ‚Üí Claude...\n",
      "[t=0.75] 835/850 ‚Üí Claude...\n",
      "[t=0.75] 836/850 ‚Üí Claude...\n",
      "[t=0.75] 837/850 ‚Üí Claude...\n",
      "[t=0.75] 838/850 ‚Üí Claude...\n",
      "[t=0.75] 839/850 ‚Üí Claude...\n",
      "[t=0.75] 840/850 ‚Üí Claude...\n",
      "üíæ Saved 2540 rows.\n",
      "[t=0.75] 841/850 ‚Üí Claude...\n",
      "[t=0.75] 842/850 ‚Üí Claude...\n",
      "[t=0.75] 843/850 ‚Üí Claude...\n",
      "[t=0.75] 844/850 ‚Üí Claude...\n",
      "[t=0.75] 845/850 ‚Üí Claude...\n",
      "[t=0.75] 846/850 ‚Üí Claude...\n",
      "[t=0.75] 847/850 ‚Üí Claude...\n",
      "[t=0.75] 848/850 ‚Üí Claude...\n",
      "[t=0.75] 849/850 ‚Üí Claude...\n",
      "[t=0.75] 850/850 ‚Üí Claude...\n",
      "üíæ Saved 2550 rows.\n",
      "\n",
      "=== Threshold t=0.9 ===\n",
      "[t=0.9] 1/850 ‚Üí Claude...\n",
      "[t=0.9] 2/850 ‚Üí Claude...\n",
      "[t=0.9] 3/850 ‚Üí Claude...\n",
      "[t=0.9] 4/850 ‚Üí Claude...\n",
      "[t=0.9] 5/850 ‚Üí Claude...\n",
      "[t=0.9] 6/850 ‚Üí Claude...\n",
      "[t=0.9] 7/850 ‚Üí Claude...\n",
      "[t=0.9] 8/850 ‚Üí Claude...\n",
      "[t=0.9] 9/850 ‚Üí Claude...\n",
      "[t=0.9] 10/850 ‚Üí Claude...\n",
      "üíæ Saved 2560 rows.\n",
      "[t=0.9] 11/850 ‚Üí Claude...\n",
      "[t=0.9] 12/850 ‚Üí Claude...\n",
      "[t=0.9] 13/850 ‚Üí Claude...\n",
      "[t=0.9] 14/850 ‚Üí Claude...\n",
      "[t=0.9] 15/850 ‚Üí Claude...\n",
      "[t=0.9] 16/850 ‚Üí Claude...\n",
      "[t=0.9] 17/850 ‚Üí Claude...\n",
      "[t=0.9] 18/850 ‚Üí Claude...\n",
      "[t=0.9] 19/850 ‚Üí Claude...\n",
      "[t=0.9] 20/850 ‚Üí Claude...\n",
      "üíæ Saved 2570 rows.\n",
      "[t=0.9] 21/850 ‚Üí Claude...\n",
      "[t=0.9] 22/850 ‚Üí Claude...\n",
      "[t=0.9] 23/850 ‚Üí Claude...\n",
      "[t=0.9] 24/850 ‚Üí Claude...\n",
      "[t=0.9] 25/850 ‚Üí Claude...\n",
      "[t=0.9] 26/850 ‚Üí Claude...\n",
      "[t=0.9] 27/850 ‚Üí Claude...\n",
      "[t=0.9] 28/850 ‚Üí Claude...\n",
      "[t=0.9] 29/850 ‚Üí Claude...\n",
      "[t=0.9] 30/850 ‚Üí Claude...\n",
      "üíæ Saved 2580 rows.\n",
      "[t=0.9] 31/850 ‚Üí Claude...\n",
      "[t=0.9] 32/850 ‚Üí Claude...\n",
      "[t=0.9] 33/850 ‚Üí Claude...\n",
      "[t=0.9] 34/850 ‚Üí Claude...\n",
      "[t=0.9] 35/850 ‚Üí Claude...\n",
      "[t=0.9] 36/850 ‚Üí Claude...\n",
      "[t=0.9] 37/850 ‚Üí Claude...\n",
      "[t=0.9] 38/850 ‚Üí Claude...\n",
      "[t=0.9] 39/850 ‚Üí Claude...\n",
      "[t=0.9] 40/850 ‚Üí Claude...\n",
      "üíæ Saved 2590 rows.\n",
      "[t=0.9] 41/850 ‚Üí Claude...\n",
      "[t=0.9] 42/850 ‚Üí Claude...\n",
      "[t=0.9] 43/850 ‚Üí Claude...\n",
      "[t=0.9] 44/850 ‚Üí Claude...\n",
      "[t=0.9] 45/850 ‚Üí Claude...\n",
      "[t=0.9] 46/850 ‚Üí Claude...\n",
      "[t=0.9] 47/850 ‚Üí Claude...\n",
      "[t=0.9] 48/850 ‚Üí Claude...\n",
      "[t=0.9] 49/850 ‚Üí Claude...\n",
      "[t=0.9] 50/850 ‚Üí Claude...\n",
      "üíæ Saved 2600 rows.\n",
      "[t=0.9] 51/850 ‚Üí Claude...\n",
      "[t=0.9] 52/850 ‚Üí Claude...\n",
      "[t=0.9] 53/850 ‚Üí Claude...\n",
      "[t=0.9] 54/850 ‚Üí Claude...\n",
      "[t=0.9] 55/850 ‚Üí Claude...\n",
      "[t=0.9] 56/850 ‚Üí Claude...\n",
      "[t=0.9] 57/850 ‚Üí Claude...\n",
      "[t=0.9] 58/850 ‚Üí Claude...\n",
      "[t=0.9] 59/850 ‚Üí Claude...\n",
      "[t=0.9] 60/850 ‚Üí Claude...\n",
      "üíæ Saved 2610 rows.\n",
      "[t=0.9] 61/850 ‚Üí Claude...\n",
      "[t=0.9] 62/850 ‚Üí Claude...\n",
      "[t=0.9] 63/850 ‚Üí Claude...\n",
      "[t=0.9] 64/850 ‚Üí Claude...\n",
      "[t=0.9] 65/850 ‚Üí Claude...\n",
      "[t=0.9] 66/850 ‚Üí Claude...\n",
      "[t=0.9] 67/850 ‚Üí Claude...\n",
      "[t=0.9] 68/850 ‚Üí Claude...\n",
      "[t=0.9] 69/850 ‚Üí Claude...\n",
      "[t=0.9] 70/850 ‚Üí Claude...\n",
      "üíæ Saved 2620 rows.\n",
      "[t=0.9] 71/850 ‚Üí Claude...\n",
      "[t=0.9] 72/850 ‚Üí Claude...\n",
      "[t=0.9] 73/850 ‚Üí Claude...\n",
      "[t=0.9] 74/850 ‚Üí Claude...\n",
      "[t=0.9] 75/850 ‚Üí Claude...\n",
      "[t=0.9] 76/850 ‚Üí Claude...\n",
      "[t=0.9] 77/850 ‚Üí Claude...\n",
      "[t=0.9] 78/850 ‚Üí Claude...\n",
      "[t=0.9] 79/850 ‚Üí Claude...\n",
      "[t=0.9] 80/850 ‚Üí Claude...\n",
      "üíæ Saved 2630 rows.\n",
      "[t=0.9] 81/850 ‚Üí Claude...\n",
      "[t=0.9] 82/850 ‚Üí Claude...\n",
      "[t=0.9] 83/850 ‚Üí Claude...\n",
      "[t=0.9] 84/850 ‚Üí Claude...\n",
      "[t=0.9] 85/850 ‚Üí Claude...\n",
      "[t=0.9] 86/850 ‚Üí Claude...\n",
      "[t=0.9] 87/850 ‚Üí Claude...\n",
      "[t=0.9] 88/850 ‚Üí Claude...\n",
      "[t=0.9] 89/850 ‚Üí Claude...\n",
      "[t=0.9] 90/850 ‚Üí Claude...\n",
      "üíæ Saved 2640 rows.\n",
      "[t=0.9] 91/850 ‚Üí Claude...\n",
      "[t=0.9] 92/850 ‚Üí Claude...\n",
      "[t=0.9] 93/850 ‚Üí Claude...\n",
      "[t=0.9] 94/850 ‚Üí Claude...\n",
      "[t=0.9] 95/850 ‚Üí Claude...\n",
      "[t=0.9] 96/850 ‚Üí Claude...\n",
      "[t=0.9] 97/850 ‚Üí Claude...\n",
      "[t=0.9] 98/850 ‚Üí Claude...\n",
      "[t=0.9] 99/850 ‚Üí Claude...\n",
      "[t=0.9] 100/850 ‚Üí Claude...\n",
      "üíæ Saved 2650 rows.\n",
      "[t=0.9] 101/850 ‚Üí Claude...\n",
      "[t=0.9] 102/850 ‚Üí Claude...\n",
      "[t=0.9] 103/850 ‚Üí Claude...\n",
      "[t=0.9] 104/850 ‚Üí Claude...\n",
      "[t=0.9] 105/850 ‚Üí Claude...\n",
      "[t=0.9] 106/850 ‚Üí Claude...\n",
      "[t=0.9] 107/850 ‚Üí Claude...\n",
      "[t=0.9] 108/850 ‚Üí Claude...\n",
      "[t=0.9] 109/850 ‚Üí Claude...\n",
      "[t=0.9] 110/850 ‚Üí Claude...\n",
      "üíæ Saved 2660 rows.\n",
      "[t=0.9] 111/850 ‚Üí Claude...\n",
      "[t=0.9] 112/850 ‚Üí Claude...\n",
      "[t=0.9] 113/850 ‚Üí Claude...\n",
      "[t=0.9] 114/850 ‚Üí Claude...\n",
      "[t=0.9] 115/850 ‚Üí Claude...\n",
      "[t=0.9] 116/850 ‚Üí Claude...\n",
      "[t=0.9] 117/850 ‚Üí Claude...\n",
      "[t=0.9] 118/850 ‚Üí Claude...\n",
      "[t=0.9] 119/850 ‚Üí Claude...\n",
      "[t=0.9] 120/850 ‚Üí Claude...\n",
      "üíæ Saved 2670 rows.\n",
      "[t=0.9] 121/850 ‚Üí Claude...\n",
      "[t=0.9] 122/850 ‚Üí Claude...\n",
      "[t=0.9] 123/850 ‚Üí Claude...\n",
      "[t=0.9] 124/850 ‚Üí Claude...\n",
      "[t=0.9] 125/850 ‚Üí Claude...\n",
      "[t=0.9] 126/850 ‚Üí Claude...\n",
      "[t=0.9] 127/850 ‚Üí Claude...\n",
      "[t=0.9] 128/850 ‚Üí Claude...\n",
      "[t=0.9] 129/850 ‚Üí Claude...\n",
      "[t=0.9] 130/850 ‚Üí Claude...\n",
      "üíæ Saved 2680 rows.\n",
      "[t=0.9] 131/850 ‚Üí Claude...\n",
      "[t=0.9] 132/850 ‚Üí Claude...\n",
      "[t=0.9] 133/850 ‚Üí Claude...\n",
      "[t=0.9] 134/850 ‚Üí Claude...\n",
      "[t=0.9] 135/850 ‚Üí Claude...\n",
      "[t=0.9] 136/850 ‚Üí Claude...\n",
      "[t=0.9] 137/850 ‚Üí Claude...\n",
      "[t=0.9] 138/850 ‚Üí Claude...\n",
      "[t=0.9] 139/850 ‚Üí Claude...\n",
      "[t=0.9] 140/850 ‚Üí Claude...\n",
      "üíæ Saved 2690 rows.\n",
      "[t=0.9] 141/850 ‚Üí Claude...\n",
      "[t=0.9] 142/850 ‚Üí Claude...\n",
      "[t=0.9] 143/850 ‚Üí Claude...\n",
      "[t=0.9] 144/850 ‚Üí Claude...\n",
      "[t=0.9] 145/850 ‚Üí Claude...\n",
      "[t=0.9] 146/850 ‚Üí Claude...\n",
      "[t=0.9] 147/850 ‚Üí Claude...\n",
      "[t=0.9] 148/850 ‚Üí Claude...\n",
      "[t=0.9] 149/850 ‚Üí Claude...\n",
      "[t=0.9] 150/850 ‚Üí Claude...\n",
      "üíæ Saved 2700 rows.\n",
      "[t=0.9] 151/850 ‚Üí Claude...\n",
      "[t=0.9] 152/850 ‚Üí Claude...\n",
      "[t=0.9] 153/850 ‚Üí Claude...\n",
      "[t=0.9] 154/850 ‚Üí Claude...\n",
      "[t=0.9] 155/850 ‚Üí Claude...\n",
      "[t=0.9] 156/850 ‚Üí Claude...\n",
      "[t=0.9] 157/850 ‚Üí Claude...\n",
      "[t=0.9] 158/850 ‚Üí Claude...\n",
      "[t=0.9] 159/850 ‚Üí Claude...\n",
      "[t=0.9] 160/850 ‚Üí Claude...\n",
      "üíæ Saved 2710 rows.\n",
      "[t=0.9] 161/850 ‚Üí Claude...\n",
      "[t=0.9] 162/850 ‚Üí Claude...\n",
      "[t=0.9] 163/850 ‚Üí Claude...\n",
      "[t=0.9] 164/850 ‚Üí Claude...\n",
      "[t=0.9] 165/850 ‚Üí Claude...\n",
      "[t=0.9] 166/850 ‚Üí Claude...\n",
      "[t=0.9] 167/850 ‚Üí Claude...\n",
      "[t=0.9] 168/850 ‚Üí Claude...\n",
      "[t=0.9] 169/850 ‚Üí Claude...\n",
      "[t=0.9] 170/850 ‚Üí Claude...\n",
      "üíæ Saved 2720 rows.\n",
      "[t=0.9] 171/850 ‚Üí Claude...\n",
      "[t=0.9] 172/850 ‚Üí Claude...\n",
      "[t=0.9] 173/850 ‚Üí Claude...\n",
      "[t=0.9] 174/850 ‚Üí Claude...\n",
      "[t=0.9] 175/850 ‚Üí Claude...\n",
      "[t=0.9] 176/850 ‚Üí Claude...\n",
      "[t=0.9] 177/850 ‚Üí Claude...\n",
      "[t=0.9] 178/850 ‚Üí Claude...\n",
      "[t=0.9] 179/850 ‚Üí Claude...\n",
      "[t=0.9] 180/850 ‚Üí Claude...\n",
      "üíæ Saved 2730 rows.\n",
      "[t=0.9] 181/850 ‚Üí Claude...\n",
      "[t=0.9] 182/850 ‚Üí Claude...\n",
      "[t=0.9] 183/850 ‚Üí Claude...\n",
      "[t=0.9] 184/850 ‚Üí Claude...\n",
      "[t=0.9] 185/850 ‚Üí Claude...\n",
      "[t=0.9] 186/850 ‚Üí Claude...\n",
      "[t=0.9] 187/850 ‚Üí Claude...\n",
      "[t=0.9] 188/850 ‚Üí Claude...\n",
      "[t=0.9] 189/850 ‚Üí Claude...\n",
      "[t=0.9] 190/850 ‚Üí Claude...\n",
      "üíæ Saved 2740 rows.\n",
      "[t=0.9] 191/850 ‚Üí Claude...\n",
      "[t=0.9] 192/850 ‚Üí Claude...\n",
      "[t=0.9] 193/850 ‚Üí Claude...\n",
      "[t=0.9] 194/850 ‚Üí Claude...\n",
      "[t=0.9] 195/850 ‚Üí Claude...\n",
      "[t=0.9] 196/850 ‚Üí Claude...\n",
      "[t=0.9] 197/850 ‚Üí Claude...\n",
      "[t=0.9] 198/850 ‚Üí Claude...\n",
      "[t=0.9] 199/850 ‚Üí Claude...\n",
      "[t=0.9] 200/850 ‚Üí Claude...\n",
      "üíæ Saved 2750 rows.\n",
      "[t=0.9] 201/850 ‚Üí Claude...\n",
      "[t=0.9] 202/850 ‚Üí Claude...\n",
      "[t=0.9] 203/850 ‚Üí Claude...\n",
      "[t=0.9] 204/850 ‚Üí Claude...\n",
      "[t=0.9] 205/850 ‚Üí Claude...\n",
      "[t=0.9] 206/850 ‚Üí Claude...\n",
      "[t=0.9] 207/850 ‚Üí Claude...\n",
      "[t=0.9] 208/850 ‚Üí Claude...\n",
      "[t=0.9] 209/850 ‚Üí Claude...\n",
      "[t=0.9] 210/850 ‚Üí Claude...\n",
      "üíæ Saved 2760 rows.\n",
      "[t=0.9] 211/850 ‚Üí Claude...\n",
      "[t=0.9] 212/850 ‚Üí Claude...\n",
      "[t=0.9] 213/850 ‚Üí Claude...\n",
      "[t=0.9] 214/850 ‚Üí Claude...\n",
      "[t=0.9] 215/850 ‚Üí Claude...\n",
      "[t=0.9] 216/850 ‚Üí Claude...\n",
      "[t=0.9] 217/850 ‚Üí Claude...\n",
      "[t=0.9] 218/850 ‚Üí Claude...\n",
      "[t=0.9] 219/850 ‚Üí Claude...\n",
      "[t=0.9] 220/850 ‚Üí Claude...\n",
      "üíæ Saved 2770 rows.\n",
      "[t=0.9] 221/850 ‚Üí Claude...\n",
      "[t=0.9] 222/850 ‚Üí Claude...\n",
      "[t=0.9] 223/850 ‚Üí Claude...\n",
      "[t=0.9] 224/850 ‚Üí Claude...\n",
      "[t=0.9] 225/850 ‚Üí Claude...\n",
      "[t=0.9] 226/850 ‚Üí Claude...\n",
      "[t=0.9] 227/850 ‚Üí Claude...\n",
      "[t=0.9] 228/850 ‚Üí Claude...\n",
      "[t=0.9] 229/850 ‚Üí Claude...\n",
      "[t=0.9] 230/850 ‚Üí Claude...\n",
      "üíæ Saved 2780 rows.\n",
      "[t=0.9] 231/850 ‚Üí Claude...\n",
      "[t=0.9] 232/850 ‚Üí Claude...\n",
      "[t=0.9] 233/850 ‚Üí Claude...\n",
      "[t=0.9] 234/850 ‚Üí Claude...\n",
      "[t=0.9] 235/850 ‚Üí Claude...\n",
      "[t=0.9] 236/850 ‚Üí Claude...\n",
      "[t=0.9] 237/850 ‚Üí Claude...\n",
      "[t=0.9] 238/850 ‚Üí Claude...\n",
      "[t=0.9] 239/850 ‚Üí Claude...\n",
      "[t=0.9] 240/850 ‚Üí Claude...\n",
      "üíæ Saved 2790 rows.\n",
      "[t=0.9] 241/850 ‚Üí Claude...\n",
      "[t=0.9] 242/850 ‚Üí Claude...\n",
      "[t=0.9] 243/850 ‚Üí Claude...\n",
      "[t=0.9] 244/850 ‚Üí Claude...\n",
      "[t=0.9] 245/850 ‚Üí Claude...\n",
      "[t=0.9] 246/850 ‚Üí Claude...\n",
      "[t=0.9] 247/850 ‚Üí Claude...\n",
      "[t=0.9] 248/850 ‚Üí Claude...\n",
      "[t=0.9] 249/850 ‚Üí Claude...\n",
      "[t=0.9] 250/850 ‚Üí Claude...\n",
      "üíæ Saved 2800 rows.\n",
      "[t=0.9] 251/850 ‚Üí Claude...\n",
      "[t=0.9] 252/850 ‚Üí Claude...\n",
      "[t=0.9] 253/850 ‚Üí Claude...\n",
      "[t=0.9] 254/850 ‚Üí Claude...\n",
      "[t=0.9] 255/850 ‚Üí Claude...\n",
      "[t=0.9] 256/850 ‚Üí Claude...\n",
      "[t=0.9] 257/850 ‚Üí Claude...\n",
      "[t=0.9] 258/850 ‚Üí Claude...\n",
      "[t=0.9] 259/850 ‚Üí Claude...\n",
      "[t=0.9] 260/850 ‚Üí Claude...\n",
      "üíæ Saved 2810 rows.\n",
      "[t=0.9] 261/850 ‚Üí Claude...\n",
      "[t=0.9] 262/850 ‚Üí Claude...\n",
      "[t=0.9] 263/850 ‚Üí Claude...\n",
      "[t=0.9] 264/850 ‚Üí Claude...\n",
      "[t=0.9] 265/850 ‚Üí Claude...\n",
      "[t=0.9] 266/850 ‚Üí Claude...\n",
      "[t=0.9] 267/850 ‚Üí Claude...\n",
      "[t=0.9] 268/850 ‚Üí Claude...\n",
      "[t=0.9] 269/850 ‚Üí Claude...\n",
      "[t=0.9] 270/850 ‚Üí Claude...\n",
      "üíæ Saved 2820 rows.\n",
      "[t=0.9] 271/850 ‚Üí Claude...\n",
      "[t=0.9] 272/850 ‚Üí Claude...\n",
      "[t=0.9] 273/850 ‚Üí Claude...\n",
      "[t=0.9] 274/850 ‚Üí Claude...\n",
      "[t=0.9] 275/850 ‚Üí Claude...\n",
      "[t=0.9] 276/850 ‚Üí Claude...\n",
      "[t=0.9] 277/850 ‚Üí Claude...\n",
      "[t=0.9] 278/850 ‚Üí Claude...\n",
      "[t=0.9] 279/850 ‚Üí Claude...\n",
      "[t=0.9] 280/850 ‚Üí Claude...\n",
      "üíæ Saved 2830 rows.\n",
      "[t=0.9] 281/850 ‚Üí Claude...\n",
      "[t=0.9] 282/850 ‚Üí Claude...\n",
      "[t=0.9] 283/850 ‚Üí Claude...\n",
      "[t=0.9] 284/850 ‚Üí Claude...\n",
      "[t=0.9] 285/850 ‚Üí Claude...\n",
      "[t=0.9] 286/850 ‚Üí Claude...\n",
      "[t=0.9] 287/850 ‚Üí Claude...\n",
      "[t=0.9] 288/850 ‚Üí Claude...\n",
      "[t=0.9] 289/850 ‚Üí Claude...\n",
      "[t=0.9] 290/850 ‚Üí Claude...\n",
      "üíæ Saved 2840 rows.\n",
      "[t=0.9] 291/850 ‚Üí Claude...\n",
      "[t=0.9] 292/850 ‚Üí Claude...\n",
      "[t=0.9] 293/850 ‚Üí Claude...\n",
      "[t=0.9] 294/850 ‚Üí Claude...\n",
      "[t=0.9] 295/850 ‚Üí Claude...\n",
      "[t=0.9] 296/850 ‚Üí Claude...\n",
      "[t=0.9] 297/850 ‚Üí Claude...\n",
      "[t=0.9] 298/850 ‚Üí Claude...\n",
      "[t=0.9] 299/850 ‚Üí Claude...\n",
      "[t=0.9] 300/850 ‚Üí Claude...\n",
      "üíæ Saved 2850 rows.\n",
      "[t=0.9] 301/850 ‚Üí Claude...\n",
      "[t=0.9] 302/850 ‚Üí Claude...\n",
      "[t=0.9] 303/850 ‚Üí Claude...\n",
      "[t=0.9] 304/850 ‚Üí Claude...\n",
      "[t=0.9] 305/850 ‚Üí Claude...\n",
      "[t=0.9] 306/850 ‚Üí Claude...\n",
      "[t=0.9] 307/850 ‚Üí Claude...\n",
      "[t=0.9] 308/850 ‚Üí Claude...\n",
      "[t=0.9] 309/850 ‚Üí Claude...\n",
      "[t=0.9] 310/850 ‚Üí Claude...\n",
      "üíæ Saved 2860 rows.\n",
      "[t=0.9] 311/850 ‚Üí Claude...\n",
      "[t=0.9] 312/850 ‚Üí Claude...\n",
      "[t=0.9] 313/850 ‚Üí Claude...\n",
      "[t=0.9] 314/850 ‚Üí Claude...\n",
      "[t=0.9] 315/850 ‚Üí Claude...\n",
      "[t=0.9] 316/850 ‚Üí Claude...\n",
      "[t=0.9] 317/850 ‚Üí Claude...\n",
      "[t=0.9] 318/850 ‚Üí Claude...\n",
      "[t=0.9] 319/850 ‚Üí Claude...\n",
      "[t=0.9] 320/850 ‚Üí Claude...\n",
      "üíæ Saved 2870 rows.\n",
      "[t=0.9] 321/850 ‚Üí Claude...\n",
      "[t=0.9] 322/850 ‚Üí Claude...\n",
      "[t=0.9] 323/850 ‚Üí Claude...\n",
      "[t=0.9] 324/850 ‚Üí Claude...\n",
      "[t=0.9] 325/850 ‚Üí Claude...\n",
      "[t=0.9] 326/850 ‚Üí Claude...\n",
      "[t=0.9] 327/850 ‚Üí Claude...\n",
      "[t=0.9] 328/850 ‚Üí Claude...\n",
      "[t=0.9] 329/850 ‚Üí Claude...\n",
      "[t=0.9] 330/850 ‚Üí Claude...\n",
      "üíæ Saved 2880 rows.\n",
      "[t=0.9] 331/850 ‚Üí Claude...\n",
      "[t=0.9] 332/850 ‚Üí Claude...\n",
      "[t=0.9] 333/850 ‚Üí Claude...\n",
      "[t=0.9] 334/850 ‚Üí Claude...\n",
      "[t=0.9] 335/850 ‚Üí Claude...\n",
      "[t=0.9] 336/850 ‚Üí Claude...\n",
      "[t=0.9] 337/850 ‚Üí Claude...\n",
      "[t=0.9] 338/850 ‚Üí Claude...\n",
      "[t=0.9] 339/850 ‚Üí Claude...\n",
      "[t=0.9] 340/850 ‚Üí Claude...\n",
      "üíæ Saved 2890 rows.\n",
      "[t=0.9] 341/850 ‚Üí Claude...\n",
      "[t=0.9] 342/850 ‚Üí Claude...\n",
      "[t=0.9] 343/850 ‚Üí Claude...\n",
      "[t=0.9] 344/850 ‚Üí Claude...\n",
      "[t=0.9] 345/850 ‚Üí Claude...\n",
      "[t=0.9] 346/850 ‚Üí Claude...\n",
      "[t=0.9] 347/850 ‚Üí Claude...\n",
      "[t=0.9] 348/850 ‚Üí Claude...\n",
      "[t=0.9] 349/850 ‚Üí Claude...\n",
      "[t=0.9] 350/850 ‚Üí Claude...\n",
      "üíæ Saved 2900 rows.\n",
      "[t=0.9] 351/850 ‚Üí Claude...\n",
      "[t=0.9] 352/850 ‚Üí Claude...\n",
      "[t=0.9] 353/850 ‚Üí Claude...\n",
      "[t=0.9] 354/850 ‚Üí Claude...\n",
      "[t=0.9] 355/850 ‚Üí Claude...\n",
      "[t=0.9] 356/850 ‚Üí Claude...\n",
      "[t=0.9] 357/850 ‚Üí Claude...\n",
      "[t=0.9] 358/850 ‚Üí Claude...\n",
      "[t=0.9] 359/850 ‚Üí Claude...\n",
      "[t=0.9] 360/850 ‚Üí Claude...\n",
      "üíæ Saved 2910 rows.\n",
      "[t=0.9] 361/850 ‚Üí Claude...\n",
      "[t=0.9] 362/850 ‚Üí Claude...\n",
      "[t=0.9] 363/850 ‚Üí Claude...\n",
      "[t=0.9] 364/850 ‚Üí Claude...\n",
      "[t=0.9] 365/850 ‚Üí Claude...\n",
      "[t=0.9] 366/850 ‚Üí Claude...\n",
      "[t=0.9] 367/850 ‚Üí Claude...\n",
      "[t=0.9] 368/850 ‚Üí Claude...\n",
      "[t=0.9] 369/850 ‚Üí Claude...\n",
      "[t=0.9] 370/850 ‚Üí Claude...\n",
      "üíæ Saved 2920 rows.\n",
      "[t=0.9] 371/850 ‚Üí Claude...\n",
      "[t=0.9] 372/850 ‚Üí Claude...\n",
      "[t=0.9] 373/850 ‚Üí Claude...\n",
      "[t=0.9] 374/850 ‚Üí Claude...\n",
      "[t=0.9] 375/850 ‚Üí Claude...\n",
      "[t=0.9] 376/850 ‚Üí Claude...\n",
      "[t=0.9] 377/850 ‚Üí Claude...\n",
      "[t=0.9] 378/850 ‚Üí Claude...\n",
      "[t=0.9] 379/850 ‚Üí Claude...\n",
      "[t=0.9] 380/850 ‚Üí Claude...\n",
      "üíæ Saved 2930 rows.\n",
      "[t=0.9] 381/850 ‚Üí Claude...\n",
      "[t=0.9] 382/850 ‚Üí Claude...\n",
      "[t=0.9] 383/850 ‚Üí Claude...\n",
      "[t=0.9] 384/850 ‚Üí Claude...\n",
      "[t=0.9] 385/850 ‚Üí Claude...\n",
      "[t=0.9] 386/850 ‚Üí Claude...\n",
      "[t=0.9] 387/850 ‚Üí Claude...\n",
      "[t=0.9] 388/850 ‚Üí Claude...\n",
      "[t=0.9] 389/850 ‚Üí Claude...\n",
      "[t=0.9] 390/850 ‚Üí Claude...\n",
      "üíæ Saved 2940 rows.\n",
      "[t=0.9] 391/850 ‚Üí Claude...\n",
      "[t=0.9] 392/850 ‚Üí Claude...\n",
      "[t=0.9] 393/850 ‚Üí Claude...\n",
      "[t=0.9] 394/850 ‚Üí Claude...\n",
      "[t=0.9] 395/850 ‚Üí Claude...\n",
      "[t=0.9] 396/850 ‚Üí Claude...\n",
      "[t=0.9] 397/850 ‚Üí Claude...\n",
      "[t=0.9] 398/850 ‚Üí Claude...\n",
      "[t=0.9] 399/850 ‚Üí Claude...\n",
      "[t=0.9] 400/850 ‚Üí Claude...\n",
      "üíæ Saved 2950 rows.\n",
      "[t=0.9] 401/850 ‚Üí Claude...\n",
      "[t=0.9] 402/850 ‚Üí Claude...\n",
      "[t=0.9] 403/850 ‚Üí Claude...\n",
      "[t=0.9] 404/850 ‚Üí Claude...\n",
      "[t=0.9] 405/850 ‚Üí Claude...\n",
      "[t=0.9] 406/850 ‚Üí Claude...\n",
      "[t=0.9] 407/850 ‚Üí Claude...\n",
      "[t=0.9] 408/850 ‚Üí Claude...\n",
      "[t=0.9] 409/850 ‚Üí Claude...\n",
      "[t=0.9] 410/850 ‚Üí Claude...\n",
      "üíæ Saved 2960 rows.\n",
      "[t=0.9] 411/850 ‚Üí Claude...\n",
      "[t=0.9] 412/850 ‚Üí Claude...\n",
      "[t=0.9] 413/850 ‚Üí Claude...\n",
      "[t=0.9] 414/850 ‚Üí Claude...\n",
      "[t=0.9] 415/850 ‚Üí Claude...\n",
      "[t=0.9] 416/850 ‚Üí Claude...\n",
      "[t=0.9] 417/850 ‚Üí Claude...\n",
      "[t=0.9] 418/850 ‚Üí Claude...\n",
      "[t=0.9] 419/850 ‚Üí Claude...\n",
      "[t=0.9] 420/850 ‚Üí Claude...\n",
      "üíæ Saved 2970 rows.\n",
      "[t=0.9] 421/850 ‚Üí Claude...\n",
      "[t=0.9] 422/850 ‚Üí Claude...\n",
      "[t=0.9] 423/850 ‚Üí Claude...\n",
      "[t=0.9] 424/850 ‚Üí Claude...\n",
      "[t=0.9] 425/850 ‚Üí Claude...\n",
      "[t=0.9] 426/850 ‚Üí Claude...\n",
      "[t=0.9] 427/850 ‚Üí Claude...\n",
      "[t=0.9] 428/850 ‚Üí Claude...\n",
      "[t=0.9] 429/850 ‚Üí Claude...\n",
      "[t=0.9] 430/850 ‚Üí Claude...\n",
      "üíæ Saved 2980 rows.\n",
      "[t=0.9] 431/850 ‚Üí Claude...\n",
      "[t=0.9] 432/850 ‚Üí Claude...\n",
      "[t=0.9] 433/850 ‚Üí Claude...\n",
      "[t=0.9] 434/850 ‚Üí Claude...\n",
      "[t=0.9] 435/850 ‚Üí Claude...\n",
      "[t=0.9] 436/850 ‚Üí Claude...\n",
      "[t=0.9] 437/850 ‚Üí Claude...\n",
      "[t=0.9] 438/850 ‚Üí Claude...\n",
      "[t=0.9] 439/850 ‚Üí Claude...\n",
      "[t=0.9] 440/850 ‚Üí Claude...\n",
      "üíæ Saved 2990 rows.\n",
      "[t=0.9] 441/850 ‚Üí Claude...\n",
      "[t=0.9] 442/850 ‚Üí Claude...\n",
      "[t=0.9] 443/850 ‚Üí Claude...\n",
      "[t=0.9] 444/850 ‚Üí Claude...\n",
      "[t=0.9] 445/850 ‚Üí Claude...\n",
      "[t=0.9] 446/850 ‚Üí Claude...\n",
      "[t=0.9] 447/850 ‚Üí Claude...\n",
      "[t=0.9] 448/850 ‚Üí Claude...\n",
      "[t=0.9] 449/850 ‚Üí Claude...\n",
      "[t=0.9] 450/850 ‚Üí Claude...\n",
      "üíæ Saved 3000 rows.\n",
      "[t=0.9] 451/850 ‚Üí Claude...\n",
      "[t=0.9] 452/850 ‚Üí Claude...\n",
      "[t=0.9] 453/850 ‚Üí Claude...\n",
      "[t=0.9] 454/850 ‚Üí Claude...\n",
      "[t=0.9] 455/850 ‚Üí Claude...\n",
      "[t=0.9] 456/850 ‚Üí Claude...\n",
      "[t=0.9] 457/850 ‚Üí Claude...\n",
      "[t=0.9] 458/850 ‚Üí Claude...\n",
      "[t=0.9] 459/850 ‚Üí Claude...\n",
      "[t=0.9] 460/850 ‚Üí Claude...\n",
      "üíæ Saved 3010 rows.\n",
      "[t=0.9] 461/850 ‚Üí Claude...\n",
      "[t=0.9] 462/850 ‚Üí Claude...\n",
      "[t=0.9] 463/850 ‚Üí Claude...\n",
      "[t=0.9] 464/850 ‚Üí Claude...\n",
      "[t=0.9] 465/850 ‚Üí Claude...\n",
      "[t=0.9] 466/850 ‚Üí Claude...\n",
      "[t=0.9] 467/850 ‚Üí Claude...\n",
      "[t=0.9] 468/850 ‚Üí Claude...\n",
      "[t=0.9] 469/850 ‚Üí Claude...\n",
      "[t=0.9] 470/850 ‚Üí Claude...\n",
      "üíæ Saved 3020 rows.\n",
      "[t=0.9] 471/850 ‚Üí Claude...\n",
      "[t=0.9] 472/850 ‚Üí Claude...\n",
      "[t=0.9] 473/850 ‚Üí Claude...\n",
      "[t=0.9] 474/850 ‚Üí Claude...\n",
      "[t=0.9] 475/850 ‚Üí Claude...\n",
      "[t=0.9] 476/850 ‚Üí Claude...\n",
      "[t=0.9] 477/850 ‚Üí Claude...\n",
      "[t=0.9] 478/850 ‚Üí Claude...\n",
      "[t=0.9] 479/850 ‚Üí Claude...\n",
      "[t=0.9] 480/850 ‚Üí Claude...\n",
      "üíæ Saved 3030 rows.\n",
      "[t=0.9] 481/850 ‚Üí Claude...\n",
      "[t=0.9] 482/850 ‚Üí Claude...\n",
      "[t=0.9] 483/850 ‚Üí Claude...\n",
      "[t=0.9] 484/850 ‚Üí Claude...\n",
      "[t=0.9] 485/850 ‚Üí Claude...\n",
      "[t=0.9] 486/850 ‚Üí Claude...\n",
      "[t=0.9] 487/850 ‚Üí Claude...\n",
      "[t=0.9] 488/850 ‚Üí Claude...\n",
      "[t=0.9] 489/850 ‚Üí Claude...\n",
      "[t=0.9] 490/850 ‚Üí Claude...\n",
      "üíæ Saved 3040 rows.\n",
      "[t=0.9] 491/850 ‚Üí Claude...\n",
      "[t=0.9] 492/850 ‚Üí Claude...\n",
      "[t=0.9] 493/850 ‚Üí Claude...\n",
      "[t=0.9] 494/850 ‚Üí Claude...\n",
      "[t=0.9] 495/850 ‚Üí Claude...\n",
      "[t=0.9] 496/850 ‚Üí Claude...\n",
      "[t=0.9] 497/850 ‚Üí Claude...\n",
      "[t=0.9] 498/850 ‚Üí Claude...\n",
      "[t=0.9] 499/850 ‚Üí Claude...\n",
      "[t=0.9] 500/850 ‚Üí Claude...\n",
      "üíæ Saved 3050 rows.\n",
      "[t=0.9] 501/850 ‚Üí Claude...\n",
      "[t=0.9] 502/850 ‚Üí Claude...\n",
      "[t=0.9] 503/850 ‚Üí Claude...\n",
      "[t=0.9] 504/850 ‚Üí Claude...\n",
      "[t=0.9] 505/850 ‚Üí Claude...\n",
      "[t=0.9] 506/850 ‚Üí Claude...\n",
      "[t=0.9] 507/850 ‚Üí Claude...\n",
      "[t=0.9] 508/850 ‚Üí Claude...\n",
      "[t=0.9] 509/850 ‚Üí Claude...\n",
      "[t=0.9] 510/850 ‚Üí Claude...\n",
      "üíæ Saved 3060 rows.\n",
      "[t=0.9] 511/850 ‚Üí Claude...\n",
      "[t=0.9] 512/850 ‚Üí Claude...\n",
      "[t=0.9] 513/850 ‚Üí Claude...\n",
      "[t=0.9] 514/850 ‚Üí Claude...\n",
      "[t=0.9] 515/850 ‚Üí Claude...\n",
      "[t=0.9] 516/850 ‚Üí Claude...\n",
      "[t=0.9] 517/850 ‚Üí Claude...\n",
      "[t=0.9] 518/850 ‚Üí Claude...\n",
      "[t=0.9] 519/850 ‚Üí Claude...\n",
      "[t=0.9] 520/850 ‚Üí Claude...\n",
      "üíæ Saved 3070 rows.\n",
      "[t=0.9] 521/850 ‚Üí Claude...\n",
      "[t=0.9] 522/850 ‚Üí Claude...\n",
      "[t=0.9] 523/850 ‚Üí Claude...\n",
      "[t=0.9] 524/850 ‚Üí Claude...\n",
      "[t=0.9] 525/850 ‚Üí Claude...\n",
      "[t=0.9] 526/850 ‚Üí Claude...\n",
      "[t=0.9] 527/850 ‚Üí Claude...\n",
      "[t=0.9] 528/850 ‚Üí Claude...\n",
      "[t=0.9] 529/850 ‚Üí Claude...\n",
      "[t=0.9] 530/850 ‚Üí Claude...\n",
      "üíæ Saved 3080 rows.\n",
      "[t=0.9] 531/850 ‚Üí Claude...\n",
      "[t=0.9] 532/850 ‚Üí Claude...\n",
      "[t=0.9] 533/850 ‚Üí Claude...\n",
      "[t=0.9] 534/850 ‚Üí Claude...\n",
      "[t=0.9] 535/850 ‚Üí Claude...\n",
      "[t=0.9] 536/850 ‚Üí Claude...\n",
      "[t=0.9] 537/850 ‚Üí Claude...\n",
      "[t=0.9] 538/850 ‚Üí Claude...\n",
      "[t=0.9] 539/850 ‚Üí Claude...\n",
      "[t=0.9] 540/850 ‚Üí Claude...\n",
      "üíæ Saved 3090 rows.\n",
      "[t=0.9] 541/850 ‚Üí Claude...\n",
      "[t=0.9] 542/850 ‚Üí Claude...\n",
      "[t=0.9] 543/850 ‚Üí Claude...\n",
      "[t=0.9] 544/850 ‚Üí Claude...\n",
      "[t=0.9] 545/850 ‚Üí Claude...\n",
      "[t=0.9] 546/850 ‚Üí Claude...\n",
      "[t=0.9] 547/850 ‚Üí Claude...\n",
      "[t=0.9] 548/850 ‚Üí Claude...\n",
      "[t=0.9] 549/850 ‚Üí Claude...\n",
      "[t=0.9] 550/850 ‚Üí Claude...\n",
      "üíæ Saved 3100 rows.\n",
      "[t=0.9] 551/850 ‚Üí Claude...\n",
      "[t=0.9] 552/850 ‚Üí Claude...\n",
      "[t=0.9] 553/850 ‚Üí Claude...\n",
      "[t=0.9] 554/850 ‚Üí Claude...\n",
      "[t=0.9] 555/850 ‚Üí Claude...\n",
      "[t=0.9] 556/850 ‚Üí Claude...\n",
      "[t=0.9] 557/850 ‚Üí Claude...\n",
      "[t=0.9] 558/850 ‚Üí Claude...\n",
      "[t=0.9] 559/850 ‚Üí Claude...\n",
      "[t=0.9] 560/850 ‚Üí Claude...\n",
      "üíæ Saved 3110 rows.\n",
      "[t=0.9] 561/850 ‚Üí Claude...\n",
      "[t=0.9] 562/850 ‚Üí Claude...\n",
      "[t=0.9] 563/850 ‚Üí Claude...\n",
      "[t=0.9] 564/850 ‚Üí Claude...\n",
      "[t=0.9] 565/850 ‚Üí Claude...\n",
      "[t=0.9] 566/850 ‚Üí Claude...\n",
      "[t=0.9] 567/850 ‚Üí Claude...\n",
      "[t=0.9] 568/850 ‚Üí Claude...\n",
      "[t=0.9] 569/850 ‚Üí Claude...\n",
      "[t=0.9] 570/850 ‚Üí Claude...\n",
      "üíæ Saved 3120 rows.\n",
      "[t=0.9] 571/850 ‚Üí Claude...\n",
      "[t=0.9] 572/850 ‚Üí Claude...\n",
      "[t=0.9] 573/850 ‚Üí Claude...\n",
      "[t=0.9] 574/850 ‚Üí Claude...\n",
      "[t=0.9] 575/850 ‚Üí Claude...\n",
      "[t=0.9] 576/850 ‚Üí Claude...\n",
      "[t=0.9] 577/850 ‚Üí Claude...\n",
      "[t=0.9] 578/850 ‚Üí Claude...\n",
      "[t=0.9] 579/850 ‚Üí Claude...\n",
      "[t=0.9] 580/850 ‚Üí Claude...\n",
      "üíæ Saved 3130 rows.\n",
      "[t=0.9] 581/850 ‚Üí Claude...\n",
      "[t=0.9] 582/850 ‚Üí Claude...\n",
      "[t=0.9] 583/850 ‚Üí Claude...\n",
      "[t=0.9] 584/850 ‚Üí Claude...\n",
      "[t=0.9] 585/850 ‚Üí Claude...\n",
      "[t=0.9] 586/850 ‚Üí Claude...\n",
      "[t=0.9] 587/850 ‚Üí Claude...\n",
      "[t=0.9] 588/850 ‚Üí Claude...\n",
      "[t=0.9] 589/850 ‚Üí Claude...\n",
      "[t=0.9] 590/850 ‚Üí Claude...\n",
      "üíæ Saved 3140 rows.\n",
      "[t=0.9] 591/850 ‚Üí Claude...\n",
      "[t=0.9] 592/850 ‚Üí Claude...\n",
      "[t=0.9] 593/850 ‚Üí Claude...\n",
      "[t=0.9] 594/850 ‚Üí Claude...\n",
      "[t=0.9] 595/850 ‚Üí Claude...\n",
      "[t=0.9] 596/850 ‚Üí Claude...\n",
      "[t=0.9] 597/850 ‚Üí Claude...\n",
      "[t=0.9] 598/850 ‚Üí Claude...\n",
      "[t=0.9] 599/850 ‚Üí Claude...\n",
      "[t=0.9] 600/850 ‚Üí Claude...\n",
      "üíæ Saved 3150 rows.\n",
      "[t=0.9] 601/850 ‚Üí Claude...\n",
      "[t=0.9] 602/850 ‚Üí Claude...\n",
      "[t=0.9] 603/850 ‚Üí Claude...\n",
      "[t=0.9] 604/850 ‚Üí Claude...\n",
      "[t=0.9] 605/850 ‚Üí Claude...\n",
      "[t=0.9] 606/850 ‚Üí Claude...\n",
      "[t=0.9] 607/850 ‚Üí Claude...\n",
      "[t=0.9] 608/850 ‚Üí Claude...\n",
      "[t=0.9] 609/850 ‚Üí Claude...\n",
      "[t=0.9] 610/850 ‚Üí Claude...\n",
      "üíæ Saved 3160 rows.\n",
      "[t=0.9] 611/850 ‚Üí Claude...\n",
      "[t=0.9] 612/850 ‚Üí Claude...\n",
      "[t=0.9] 613/850 ‚Üí Claude...\n",
      "[t=0.9] 614/850 ‚Üí Claude...\n",
      "[t=0.9] 615/850 ‚Üí Claude...\n",
      "[t=0.9] 616/850 ‚Üí Claude...\n",
      "[t=0.9] 617/850 ‚Üí Claude...\n",
      "[t=0.9] 618/850 ‚Üí Claude...\n",
      "[t=0.9] 619/850 ‚Üí Claude...\n",
      "[t=0.9] 620/850 ‚Üí Claude...\n",
      "üíæ Saved 3170 rows.\n",
      "[t=0.9] 621/850 ‚Üí Claude...\n",
      "[t=0.9] 622/850 ‚Üí Claude...\n",
      "[t=0.9] 623/850 ‚Üí Claude...\n",
      "[t=0.9] 624/850 ‚Üí Claude...\n",
      "[t=0.9] 625/850 ‚Üí Claude...\n",
      "[t=0.9] 626/850 ‚Üí Claude...\n",
      "[t=0.9] 627/850 ‚Üí Claude...\n",
      "[t=0.9] 628/850 ‚Üí Claude...\n",
      "[t=0.9] 629/850 ‚Üí Claude...\n",
      "[t=0.9] 630/850 ‚Üí Claude...\n",
      "üíæ Saved 3180 rows.\n",
      "[t=0.9] 631/850 ‚Üí Claude...\n",
      "[t=0.9] 632/850 ‚Üí Claude...\n",
      "[t=0.9] 633/850 ‚Üí Claude...\n",
      "[t=0.9] 634/850 ‚Üí Claude...\n",
      "[t=0.9] 635/850 ‚Üí Claude...\n",
      "[t=0.9] 636/850 ‚Üí Claude...\n",
      "[t=0.9] 637/850 ‚Üí Claude...\n",
      "[t=0.9] 638/850 ‚Üí Claude...\n",
      "[t=0.9] 639/850 ‚Üí Claude...\n",
      "[t=0.9] 640/850 ‚Üí Claude...\n",
      "üíæ Saved 3190 rows.\n",
      "[t=0.9] 641/850 ‚Üí Claude...\n",
      "[t=0.9] 642/850 ‚Üí Claude...\n",
      "[t=0.9] 643/850 ‚Üí Claude...\n",
      "[t=0.9] 644/850 ‚Üí Claude...\n",
      "[t=0.9] 645/850 ‚Üí Claude...\n",
      "[t=0.9] 646/850 ‚Üí Claude...\n",
      "[t=0.9] 647/850 ‚Üí Claude...\n",
      "[t=0.9] 648/850 ‚Üí Claude...\n",
      "[t=0.9] 649/850 ‚Üí Claude...\n",
      "[t=0.9] 650/850 ‚Üí Claude...\n",
      "üíæ Saved 3200 rows.\n",
      "[t=0.9] 651/850 ‚Üí Claude...\n",
      "[t=0.9] 652/850 ‚Üí Claude...\n",
      "[t=0.9] 653/850 ‚Üí Claude...\n",
      "[t=0.9] 654/850 ‚Üí Claude...\n",
      "[t=0.9] 655/850 ‚Üí Claude...\n",
      "[t=0.9] 656/850 ‚Üí Claude...\n",
      "[t=0.9] 657/850 ‚Üí Claude...\n",
      "[t=0.9] 658/850 ‚Üí Claude...\n",
      "[t=0.9] 659/850 ‚Üí Claude...\n",
      "[t=0.9] 660/850 ‚Üí Claude...\n",
      "üíæ Saved 3210 rows.\n",
      "[t=0.9] 661/850 ‚Üí Claude...\n",
      "[t=0.9] 662/850 ‚Üí Claude...\n",
      "[t=0.9] 663/850 ‚Üí Claude...\n",
      "[t=0.9] 664/850 ‚Üí Claude...\n",
      "[t=0.9] 665/850 ‚Üí Claude...\n",
      "[t=0.9] 666/850 ‚Üí Claude...\n",
      "[t=0.9] 667/850 ‚Üí Claude...\n",
      "[t=0.9] 668/850 ‚Üí Claude...\n",
      "[t=0.9] 669/850 ‚Üí Claude...\n",
      "[t=0.9] 670/850 ‚Üí Claude...\n",
      "üíæ Saved 3220 rows.\n",
      "[t=0.9] 671/850 ‚Üí Claude...\n",
      "[t=0.9] 672/850 ‚Üí Claude...\n",
      "[t=0.9] 673/850 ‚Üí Claude...\n",
      "[t=0.9] 674/850 ‚Üí Claude...\n",
      "[t=0.9] 675/850 ‚Üí Claude...\n",
      "[t=0.9] 676/850 ‚Üí Claude...\n",
      "[t=0.9] 677/850 ‚Üí Claude...\n",
      "[t=0.9] 678/850 ‚Üí Claude...\n",
      "[t=0.9] 679/850 ‚Üí Claude...\n",
      "[t=0.9] 680/850 ‚Üí Claude...\n",
      "üíæ Saved 3230 rows.\n",
      "[t=0.9] 681/850 ‚Üí Claude...\n",
      "[t=0.9] 682/850 ‚Üí Claude...\n",
      "[t=0.9] 683/850 ‚Üí Claude...\n",
      "[t=0.9] 684/850 ‚Üí Claude...\n",
      "[t=0.9] 685/850 ‚Üí Claude...\n",
      "[t=0.9] 686/850 ‚Üí Claude...\n",
      "[t=0.9] 687/850 ‚Üí Claude...\n",
      "[t=0.9] 688/850 ‚Üí Claude...\n",
      "[t=0.9] 689/850 ‚Üí Claude...\n",
      "[t=0.9] 690/850 ‚Üí Claude...\n",
      "üíæ Saved 3240 rows.\n",
      "[t=0.9] 691/850 ‚Üí Claude...\n",
      "[t=0.9] 692/850 ‚Üí Claude...\n",
      "[t=0.9] 693/850 ‚Üí Claude...\n",
      "[t=0.9] 694/850 ‚Üí Claude...\n",
      "[t=0.9] 695/850 ‚Üí Claude...\n",
      "[t=0.9] 696/850 ‚Üí Claude...\n",
      "[t=0.9] 697/850 ‚Üí Claude...\n",
      "[t=0.9] 698/850 ‚Üí Claude...\n",
      "[t=0.9] 699/850 ‚Üí Claude...\n",
      "[t=0.9] 700/850 ‚Üí Claude...\n",
      "üíæ Saved 3250 rows.\n",
      "[t=0.9] 701/850 ‚Üí Claude...\n",
      "[t=0.9] 702/850 ‚Üí Claude...\n",
      "[t=0.9] 703/850 ‚Üí Claude...\n",
      "[t=0.9] 704/850 ‚Üí Claude...\n",
      "[t=0.9] 705/850 ‚Üí Claude...\n",
      "[t=0.9] 706/850 ‚Üí Claude...\n",
      "[t=0.9] 707/850 ‚Üí Claude...\n",
      "[t=0.9] 708/850 ‚Üí Claude...\n",
      "[t=0.9] 709/850 ‚Üí Claude...\n",
      "[t=0.9] 710/850 ‚Üí Claude...\n",
      "üíæ Saved 3260 rows.\n",
      "[t=0.9] 711/850 ‚Üí Claude...\n",
      "[t=0.9] 712/850 ‚Üí Claude...\n",
      "[t=0.9] 713/850 ‚Üí Claude...\n",
      "[t=0.9] 714/850 ‚Üí Claude...\n",
      "[t=0.9] 715/850 ‚Üí Claude...\n",
      "[t=0.9] 716/850 ‚Üí Claude...\n",
      "[t=0.9] 717/850 ‚Üí Claude...\n",
      "[t=0.9] 718/850 ‚Üí Claude...\n",
      "[t=0.9] 719/850 ‚Üí Claude...\n",
      "[t=0.9] 720/850 ‚Üí Claude...\n",
      "üíæ Saved 3270 rows.\n",
      "[t=0.9] 721/850 ‚Üí Claude...\n",
      "[t=0.9] 722/850 ‚Üí Claude...\n",
      "[t=0.9] 723/850 ‚Üí Claude...\n",
      "[t=0.9] 724/850 ‚Üí Claude...\n",
      "[t=0.9] 725/850 ‚Üí Claude...\n",
      "[t=0.9] 726/850 ‚Üí Claude...\n",
      "[t=0.9] 727/850 ‚Üí Claude...\n",
      "[t=0.9] 728/850 ‚Üí Claude...\n",
      "[t=0.9] 729/850 ‚Üí Claude...\n",
      "[t=0.9] 730/850 ‚Üí Claude...\n",
      "üíæ Saved 3280 rows.\n",
      "[t=0.9] 731/850 ‚Üí Claude...\n",
      "[t=0.9] 732/850 ‚Üí Claude...\n",
      "[t=0.9] 733/850 ‚Üí Claude...\n",
      "[t=0.9] 734/850 ‚Üí Claude...\n",
      "[t=0.9] 735/850 ‚Üí Claude...\n",
      "[t=0.9] 736/850 ‚Üí Claude...\n",
      "[t=0.9] 737/850 ‚Üí Claude...\n",
      "[t=0.9] 738/850 ‚Üí Claude...\n",
      "[t=0.9] 739/850 ‚Üí Claude...\n",
      "[t=0.9] 740/850 ‚Üí Claude...\n",
      "üíæ Saved 3290 rows.\n",
      "[t=0.9] 741/850 ‚Üí Claude...\n",
      "[t=0.9] 742/850 ‚Üí Claude...\n",
      "[t=0.9] 743/850 ‚Üí Claude...\n",
      "[t=0.9] 744/850 ‚Üí Claude...\n",
      "[t=0.9] 745/850 ‚Üí Claude...\n",
      "[t=0.9] 746/850 ‚Üí Claude...\n",
      "[t=0.9] 747/850 ‚Üí Claude...\n",
      "[t=0.9] 748/850 ‚Üí Claude...\n",
      "[t=0.9] 749/850 ‚Üí Claude...\n",
      "[t=0.9] 750/850 ‚Üí Claude...\n",
      "üíæ Saved 3300 rows.\n",
      "[t=0.9] 751/850 ‚Üí Claude...\n",
      "[t=0.9] 752/850 ‚Üí Claude...\n",
      "[t=0.9] 753/850 ‚Üí Claude...\n",
      "[t=0.9] 754/850 ‚Üí Claude...\n",
      "[t=0.9] 755/850 ‚Üí Claude...\n",
      "[t=0.9] 756/850 ‚Üí Claude...\n",
      "[t=0.9] 757/850 ‚Üí Claude...\n",
      "[t=0.9] 758/850 ‚Üí Claude...\n",
      "[t=0.9] 759/850 ‚Üí Claude...\n",
      "[t=0.9] 760/850 ‚Üí Claude...\n",
      "üíæ Saved 3310 rows.\n",
      "[t=0.9] 761/850 ‚Üí Claude...\n",
      "[t=0.9] 762/850 ‚Üí Claude...\n",
      "[t=0.9] 763/850 ‚Üí Claude...\n",
      "[t=0.9] 764/850 ‚Üí Claude...\n",
      "[t=0.9] 765/850 ‚Üí Claude...\n",
      "[t=0.9] 766/850 ‚Üí Claude...\n",
      "[t=0.9] 767/850 ‚Üí Claude...\n",
      "[t=0.9] 768/850 ‚Üí Claude...\n",
      "[t=0.9] 769/850 ‚Üí Claude...\n",
      "[t=0.9] 770/850 ‚Üí Claude...\n",
      "üíæ Saved 3320 rows.\n",
      "[t=0.9] 771/850 ‚Üí Claude...\n",
      "[t=0.9] 772/850 ‚Üí Claude...\n",
      "[t=0.9] 773/850 ‚Üí Claude...\n",
      "[t=0.9] 774/850 ‚Üí Claude...\n",
      "[t=0.9] 775/850 ‚Üí Claude...\n",
      "[t=0.9] 776/850 ‚Üí Claude...\n",
      "[t=0.9] 777/850 ‚Üí Claude...\n",
      "[t=0.9] 778/850 ‚Üí Claude...\n",
      "[t=0.9] 779/850 ‚Üí Claude...\n",
      "[t=0.9] 780/850 ‚Üí Claude...\n",
      "üíæ Saved 3330 rows.\n",
      "[t=0.9] 781/850 ‚Üí Claude...\n",
      "[t=0.9] 782/850 ‚Üí Claude...\n",
      "[t=0.9] 783/850 ‚Üí Claude...\n",
      "[t=0.9] 784/850 ‚Üí Claude...\n",
      "[t=0.9] 785/850 ‚Üí Claude...\n",
      "[t=0.9] 786/850 ‚Üí Claude...\n",
      "[t=0.9] 787/850 ‚Üí Claude...\n",
      "[t=0.9] 788/850 ‚Üí Claude...\n",
      "[t=0.9] 789/850 ‚Üí Claude...\n",
      "[t=0.9] 790/850 ‚Üí Claude...\n",
      "üíæ Saved 3340 rows.\n",
      "[t=0.9] 791/850 ‚Üí Claude...\n",
      "[t=0.9] 792/850 ‚Üí Claude...\n",
      "[t=0.9] 793/850 ‚Üí Claude...\n",
      "[t=0.9] 794/850 ‚Üí Claude...\n",
      "[t=0.9] 795/850 ‚Üí Claude...\n",
      "[t=0.9] 796/850 ‚Üí Claude...\n",
      "[t=0.9] 797/850 ‚Üí Claude...\n",
      "[t=0.9] 798/850 ‚Üí Claude...\n",
      "[t=0.9] 799/850 ‚Üí Claude...\n",
      "[t=0.9] 800/850 ‚Üí Claude...\n",
      "üíæ Saved 3350 rows.\n",
      "[t=0.9] 801/850 ‚Üí Claude...\n",
      "[t=0.9] 802/850 ‚Üí Claude...\n",
      "[t=0.9] 803/850 ‚Üí Claude...\n",
      "[t=0.9] 804/850 ‚Üí Claude...\n",
      "[t=0.9] 805/850 ‚Üí Claude...\n",
      "[t=0.9] 806/850 ‚Üí Claude...\n",
      "[t=0.9] 807/850 ‚Üí Claude...\n",
      "[t=0.9] 808/850 ‚Üí Claude...\n",
      "[t=0.9] 809/850 ‚Üí Claude...\n",
      "[t=0.9] 810/850 ‚Üí Claude...\n",
      "üíæ Saved 3360 rows.\n",
      "[t=0.9] 811/850 ‚Üí Claude...\n",
      "[t=0.9] 812/850 ‚Üí Claude...\n",
      "[t=0.9] 813/850 ‚Üí Claude...\n",
      "[t=0.9] 814/850 ‚Üí Claude...\n",
      "[t=0.9] 815/850 ‚Üí Claude...\n",
      "[t=0.9] 816/850 ‚Üí Claude...\n",
      "[t=0.9] 817/850 ‚Üí Claude...\n",
      "[t=0.9] 818/850 ‚Üí Claude...\n",
      "[t=0.9] 819/850 ‚Üí Claude...\n",
      "[t=0.9] 820/850 ‚Üí Claude...\n",
      "üíæ Saved 3370 rows.\n",
      "[t=0.9] 821/850 ‚Üí Claude...\n",
      "[t=0.9] 822/850 ‚Üí Claude...\n",
      "[t=0.9] 823/850 ‚Üí Claude...\n",
      "[t=0.9] 824/850 ‚Üí Claude...\n",
      "[t=0.9] 825/850 ‚Üí Claude...\n",
      "[t=0.9] 826/850 ‚Üí Claude...\n",
      "[t=0.9] 827/850 ‚Üí Claude...\n",
      "[t=0.9] 828/850 ‚Üí Claude...\n",
      "[t=0.9] 829/850 ‚Üí Claude...\n",
      "[t=0.9] 830/850 ‚Üí Claude...\n",
      "üíæ Saved 3380 rows.\n",
      "[t=0.9] 831/850 ‚Üí Claude...\n",
      "[t=0.9] 832/850 ‚Üí Claude...\n",
      "[t=0.9] 833/850 ‚Üí Claude...\n",
      "[t=0.9] 834/850 ‚Üí Claude...\n",
      "[t=0.9] 835/850 ‚Üí Claude...\n",
      "[t=0.9] 836/850 ‚Üí Claude...\n",
      "[t=0.9] 837/850 ‚Üí Claude...\n",
      "[t=0.9] 838/850 ‚Üí Claude...\n",
      "[t=0.9] 839/850 ‚Üí Claude...\n",
      "[t=0.9] 840/850 ‚Üí Claude...\n",
      "üíæ Saved 3390 rows.\n",
      "[t=0.9] 841/850 ‚Üí Claude...\n",
      "[t=0.9] 842/850 ‚Üí Claude...\n",
      "[t=0.9] 843/850 ‚Üí Claude...\n",
      "[t=0.9] 844/850 ‚Üí Claude...\n",
      "[t=0.9] 845/850 ‚Üí Claude...\n",
      "[t=0.9] 846/850 ‚Üí Claude...\n",
      "[t=0.9] 847/850 ‚Üí Claude...\n",
      "[t=0.9] 848/850 ‚Üí Claude...\n",
      "[t=0.9] 849/850 ‚Üí Claude...\n",
      "[t=0.9] 850/850 ‚Üí Claude...\n",
      "üíæ Saved 3400 rows.\n",
      "saved: /Users/stutisinghal/Documents/fall25/NLP/final/final_branch/cloned_final/llm-eval/inference/outputs/claude-mmlu.csv\n"
     ]
    }
   ],
   "source": [
    "for t in THRESHOLDS:\n",
    "    print(f\"\\n=== Threshold t={t} ===\")\n",
    "\n",
    "    for idx, row in eval_df.iterrows():\n",
    "        key = (row[\"id\"], float(t))\n",
    "        if key in done_pairs:\n",
    "            continue\n",
    "\n",
    "        prompt = build_mcq_prompt(row, t)\n",
    "\n",
    "        print(f\"[t={t}] {idx+1}/{total} ‚Üí Claude...\")\n",
    "\n",
    "        pred, conf = claude_answer_and_conf(prompt)\n",
    "\n",
    "        saved_rows.append({\n",
    "            \"id\": row[\"id\"],\n",
    "            \"threshold\": t,\n",
    "            \"question\": row[\"question\"],\n",
    "            \"choices\": row[\"choices\"],\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"predicted_answer\": pred,\n",
    "            \"confidence\": conf\n",
    "        })\n",
    "\n",
    "        done_pairs.add(key)\n",
    "        new_since_save += 1\n",
    "\n",
    "        # SAVE EVERY 10\n",
    "        if new_since_save >= SAVE_EVERY:\n",
    "            pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "            print(f\"üíæ Saved {len(saved_rows)} rows.\")\n",
    "            new_since_save = 0\n",
    "\n",
    "# Final save\n",
    "pd.DataFrame(saved_rows).to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"saved:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b05d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73006996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
