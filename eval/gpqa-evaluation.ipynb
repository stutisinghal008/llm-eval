{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22de04fa",
   "metadata": {},
   "source": [
    "## Imports, Setup, Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "THRESHOLDS = [0.25, 0.5, 0.75, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide(p: float, t: float) -> bool:\n",
    "    # decision rule: True if model answers\n",
    "    # assumption: model only answers when p > t\n",
    "    return p > t\n",
    "\n",
    "\n",
    "def penalty_score(pred: str, gold: str, p: float, t: float) -> float:\n",
    "    # our penalty adjusted scoring\n",
    "    # if p <= t -> the model abstains -> score = 0.\n",
    "    # if p > t and prediction == gold -> score = +1.\n",
    "    # if p > t and prediction != gold -> score = - (p * t) / (1 - t)\n",
    "    if p <= t:\n",
    "        return 0.0\n",
    "    if pred == gold:\n",
    "        return 1.0\n",
    "    return round(- (p * t) / (1.0 - t),2)\n",
    "\n",
    "\n",
    "def accuracy_at_threshold(df: pd.DataFrame, t: float) -> float:\n",
    "    # fraction of answered questions that are correct\n",
    "    # acc@t = (correct with p>t) / (# answered with p>t)\n",
    "    answered = df[\"confidence\"] > t\n",
    "    answered_n = answered.sum()\n",
    "    if answered_n == 0:\n",
    "        return 0.0\n",
    "    correct = (df[\"predicted_answer\"] == df[\"answer\"]) & answered\n",
    "    return round(100*float(correct.sum() / answered_n),2)\n",
    "\n",
    "def coverage(df: pd.DataFrame, t: float) -> float:\n",
    "    # frac of total questions the model answers\n",
    "    # cov = (# p>t) / total\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return 0.0\n",
    "    return round(100*float((df[\"confidence\"] > t).sum() / len(df)),2)\n",
    "\n",
    "def penalty_adjusted_mean(df: pd.DataFrame, t: float) -> float:\n",
    "    # mean penalty-adjusted score across all rows \n",
    "    # includes abstains = 0\n",
    "\n",
    "    scores = [\n",
    "        penalty_score(r.predicted_answer, r.answer, float(r.confidence), t)\n",
    "        for r in df.itertuples(index=False)\n",
    "    ]\n",
    "    return round(float(np.mean(scores)) if scores else 0.0,2)\n",
    "\n",
    "def overconfidence_rate(df: pd.DataFrame, t: float) -> float:\n",
    "    # fraction of questions where the model is wrong but p>t\n",
    "    # over = (# wrong & p>t) / total\n",
    "    if len(df) == 0:\n",
    "        return 0.0\n",
    "    mask = (df[\"predicted_answer\"] != df[\"answer\"]) & (df[\"confidence\"] > t)\n",
    "    return round(100*float(mask.sum() / len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8856ef",
   "metadata": {},
   "source": [
    "## Qwen Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05093db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/qwen-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45874a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from qwen-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>IDK</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>IDK</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D              IDK   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A                B   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A              IDK   \n",
       "\n",
       "   confidence  \n",
       "0       66.67  \n",
       "1      100.00  \n",
       "2      100.00  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60390b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "      <th>answered_n</th>\n",
       "      <th>total_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5.74</td>\n",
       "      <td>95.69</td>\n",
       "      <td>-28.31</td>\n",
       "      <td>90</td>\n",
       "      <td>244</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>4.53</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-85.05</td>\n",
       "      <td>91</td>\n",
       "      <td>243</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>6.58</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-254.84</td>\n",
       "      <td>89</td>\n",
       "      <td>243</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>4.96</td>\n",
       "      <td>94.90</td>\n",
       "      <td>-763.72</td>\n",
       "      <td>90</td>\n",
       "      <td>242</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy_at_t  coverage  penalty_mean  overconf_rate  \\\n",
       "0       0.25           5.74     95.69        -28.31             90   \n",
       "1       0.50           4.53     95.29        -85.05             91   \n",
       "2       0.75           6.58     95.29       -254.84             89   \n",
       "3       0.90           4.96     94.90       -763.72             90   \n",
       "\n",
       "   answered_n  total_n  \n",
       "0         244      255  \n",
       "1         243      255  \n",
       "2         243      255  \n",
       "3         242      255  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": round(overconfidence_rate(df_t, t),2),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73099b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>5.74</td>\n",
       "      <td>95.69</td>\n",
       "      <td>-28.31</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>4.53</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-85.05</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>6.58</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-254.84</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>4.96</td>\n",
       "      <td>94.90</td>\n",
       "      <td>-763.72</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25                5.74     95.69        -28.31             90\n",
       "0.50                4.53     95.29        -85.05             91\n",
       "0.75                6.58     95.29       -254.84             89\n",
       "0.90                4.96     94.90       -763.72             90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"qwen-gpqa-metric-eval.csv\")\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbf7a9",
   "metadata": {},
   "source": [
    "## Baseline Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "441e6909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>5.74</td>\n",
       "      <td>95.69</td>\n",
       "      <td>-28.31</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>4.53</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-85.05</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>6.58</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-254.84</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>4.96</td>\n",
       "      <td>94.90</td>\n",
       "      <td>-763.72</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25                5.74     95.69        -28.31             90\n",
       "0.50                4.53     95.29        -85.05             91\n",
       "0.75                6.58     95.29       -254.84             89\n",
       "0.90                4.96     94.90       -763.72             90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t      6.58\n",
       "coverage          95.29\n",
       "penalty_mean    -254.84\n",
       "overconf_rate     89.00\n",
       "Name: 0.75, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ec9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary            5.2       1.0           NaN           94.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "wrong_rate = 1 - binary_acc\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,  \n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.75)</th>\n",
       "      <td>6.58</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-254.84</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>5.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.75)           6.58     95.29       -254.84   \n",
       "Binary grading                       5.20      1.00           NaN   \n",
       "Always abstain                       0.00      0.00          0.00   \n",
       "\n",
       "                            overconf_rate  \n",
       "Confidence-aware (t*=0.75)           89.0  \n",
       "Binary grading                       94.8  \n",
       "Always abstain                        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"qwen-gpqa-baseline-eval.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf67fdc",
   "metadata": {},
   "source": [
    "## GPT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d50c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/gpt-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from gpt-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D                B   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A                D   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A                A   \n",
       "\n",
       "   confidence  \n",
       "0       66.67  \n",
       "1       66.67  \n",
       "2      100.00  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ec340",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": overconfidence_rate(df_t, t),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>33.46</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-18.22</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>33.86</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-54.24</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>29.92</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-172.33</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>31.10</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-506.22</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               33.46     99.61        -18.22             66\n",
       "0.50               33.86     99.61        -54.24             66\n",
       "0.75               29.92     99.61       -172.33             70\n",
       "0.90               31.10     99.61       -506.22             69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"gpt-gpqa-metric-eval.csv\")\n",
    "\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85e3cb",
   "metadata": {},
   "source": [
    "### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d837711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>33.46</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-18.22</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>33.86</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-54.24</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>29.92</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-172.33</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>31.10</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-506.22</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               33.46     99.61        -18.22             66\n",
       "0.50               33.86     99.61        -54.24             66\n",
       "0.75               29.92     99.61       -172.33             70\n",
       "0.90               31.10     99.61       -506.22             69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t    33.86\n",
       "coverage         99.61\n",
       "penalty_mean    -54.24\n",
       "overconf_rate    66.00\n",
       "Name: 0.5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad8958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>31.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary          31.96       1.0           NaN          68.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "\n",
    "wrong_rate = 1 - binary_acc\n",
    "\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,\n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5273cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.5)</th>\n",
       "      <td>33.86</td>\n",
       "      <td>99.61</td>\n",
       "      <td>-54.24</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>31.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.5)          33.86     99.61        -54.24   \n",
       "Binary grading                     31.96      1.00           NaN   \n",
       "Always abstain                      0.00      0.00          0.00   \n",
       "\n",
       "                           overconf_rate  \n",
       "Confidence-aware (t*=0.5)          66.00  \n",
       "Binary grading                     68.04  \n",
       "Always abstain                      0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"gpt-gpqa-baseline-eval.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776445b",
   "metadata": {},
   "source": [
    "## Claude Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eaaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/claude-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e20a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from claude-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>I</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D                I   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A                I   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A                I   \n",
       "\n",
       "   confidence  \n",
       "0       100.0  \n",
       "1       100.0  \n",
       "2       100.0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ed9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": overconfidence_rate(df_t, t),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>3.43</td>\n",
       "      <td>91.37</td>\n",
       "      <td>-29.08</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>2.92</td>\n",
       "      <td>94.12</td>\n",
       "      <td>-89.08</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2.88</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-276.31</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>2.44</td>\n",
       "      <td>96.47</td>\n",
       "      <td>-839.27</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25                3.43     91.37        -29.08             88\n",
       "0.50                2.92     94.12        -89.08             91\n",
       "0.75                2.88     95.29       -276.31             93\n",
       "0.90                2.44     96.47       -839.27             94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"claude-gpqa-metric-eval.csv\")\n",
    "\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847243d",
   "metadata": {},
   "source": [
    "### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa6ae463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>3.43</td>\n",
       "      <td>91.37</td>\n",
       "      <td>-29.08</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>2.92</td>\n",
       "      <td>94.12</td>\n",
       "      <td>-89.08</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2.88</td>\n",
       "      <td>95.29</td>\n",
       "      <td>-276.31</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>2.44</td>\n",
       "      <td>96.47</td>\n",
       "      <td>-839.27</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25                3.43     91.37        -29.08             88\n",
       "0.50                2.92     94.12        -89.08             91\n",
       "0.75                2.88     95.29       -276.31             93\n",
       "0.90                2.44     96.47       -839.27             94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t     3.43\n",
       "coverage         91.37\n",
       "penalty_mean    -29.08\n",
       "overconf_rate    88.00\n",
       "Name: 0.25, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>2.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary           2.75       1.0           NaN          97.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "\n",
    "wrong_rate = 1 - binary_acc\n",
    "\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,\n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2214bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.25)</th>\n",
       "      <td>3.43</td>\n",
       "      <td>91.37</td>\n",
       "      <td>-29.08</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>2.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.25)           3.43     91.37        -29.08   \n",
       "Binary grading                       2.75      1.00           NaN   \n",
       "Always abstain                       0.00      0.00          0.00   \n",
       "\n",
       "                            overconf_rate  \n",
       "Confidence-aware (t*=0.25)          88.00  \n",
       "Binary grading                      97.25  \n",
       "Always abstain                       0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"claude-gpqa-baseline-eval.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da187c",
   "metadata": {},
   "source": [
    "## LLama Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbf33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/llama-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from llama-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>IDK</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D                T   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A              IDK   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A                A   \n",
       "\n",
       "   confidence  \n",
       "0      100.00  \n",
       "1        0.00  \n",
       "2       66.67  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5141ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": overconfidence_rate(df_t, t),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b616ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>10.83</td>\n",
       "      <td>61.57</td>\n",
       "      <td>-15.80</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>10.78</td>\n",
       "      <td>65.49</td>\n",
       "      <td>-50.78</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>11.54</td>\n",
       "      <td>61.18</td>\n",
       "      <td>-139.44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>13.12</td>\n",
       "      <td>62.75</td>\n",
       "      <td>-412.68</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               10.83     61.57        -15.80             55\n",
       "0.50               10.78     65.49        -50.78             58\n",
       "0.75               11.54     61.18       -139.44             54\n",
       "0.90               13.12     62.75       -412.68             55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"llama-gpqa-metric-eval.csv\")\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e6127",
   "metadata": {},
   "source": [
    "### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c46e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>10.83</td>\n",
       "      <td>61.57</td>\n",
       "      <td>-15.80</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>10.78</td>\n",
       "      <td>65.49</td>\n",
       "      <td>-50.78</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>11.54</td>\n",
       "      <td>61.18</td>\n",
       "      <td>-139.44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>13.12</td>\n",
       "      <td>62.75</td>\n",
       "      <td>-412.68</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               10.83     61.57        -15.80             55\n",
       "0.50               10.78     65.49        -50.78             58\n",
       "0.75               11.54     61.18       -139.44             54\n",
       "0.90               13.12     62.75       -412.68             55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t     13.12\n",
       "coverage          62.75\n",
       "penalty_mean    -412.68\n",
       "overconf_rate     55.00\n",
       "Name: 0.9, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>7.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary           7.25       1.0           NaN          92.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "\n",
    "wrong_rate = 1 - binary_acc\n",
    "\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,\n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530da1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.9)</th>\n",
       "      <td>13.12</td>\n",
       "      <td>62.75</td>\n",
       "      <td>-412.68</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>7.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.9)          13.12     62.75       -412.68   \n",
       "Binary grading                      7.25      1.00           NaN   \n",
       "Always abstain                      0.00      0.00          0.00   \n",
       "\n",
       "                           overconf_rate  \n",
       "Confidence-aware (t*=0.9)          55.00  \n",
       "Binary grading                     92.75  \n",
       "Always abstain                      0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"llama-gpqa-baseline-eval.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929f4c4",
   "metadata": {},
   "source": [
    "## Gemini Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/gemini-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99771df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from gemini-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>IDK</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>IDK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D              IDK   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A                C   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A              IDK   \n",
       "\n",
       "   confidence  \n",
       "0       100.0  \n",
       "1        75.0  \n",
       "2         0.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da06947",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": overconfidence_rate(df_t, t),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ce6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>20.71</td>\n",
       "      <td>54.90</td>\n",
       "      <td>-12.92</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>21.53</td>\n",
       "      <td>56.47</td>\n",
       "      <td>-39.32</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>22.92</td>\n",
       "      <td>56.47</td>\n",
       "      <td>-118.60</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>20.69</td>\n",
       "      <td>56.86</td>\n",
       "      <td>-376.47</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               20.71     54.90        -12.92             44\n",
       "0.50               21.53     56.47        -39.32             44\n",
       "0.75               22.92     56.47       -118.60             44\n",
       "0.90               20.69     56.86       -376.47             45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"gemini-gpqa-metric-eval.csv\")\n",
    "\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1292174",
   "metadata": {},
   "source": [
    "### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5cc6cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>20.71</td>\n",
       "      <td>54.90</td>\n",
       "      <td>-12.92</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>21.53</td>\n",
       "      <td>56.47</td>\n",
       "      <td>-39.32</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>22.92</td>\n",
       "      <td>56.47</td>\n",
       "      <td>-118.60</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>20.69</td>\n",
       "      <td>56.86</td>\n",
       "      <td>-376.47</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               20.71     54.90        -12.92             44\n",
       "0.50               21.53     56.47        -39.32             44\n",
       "0.75               22.92     56.47       -118.60             44\n",
       "0.90               20.69     56.86       -376.47             45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t     22.92\n",
       "coverage          56.47\n",
       "penalty_mean    -118.60\n",
       "overconf_rate     44.00\n",
       "Name: 0.75, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a8322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>12.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary          12.06       1.0           NaN          87.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "\n",
    "wrong_rate = 1 - binary_acc\n",
    "\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,\n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abc100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.75)</th>\n",
       "      <td>22.92</td>\n",
       "      <td>56.47</td>\n",
       "      <td>-118.6</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>12.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.75)          22.92     56.47        -118.6   \n",
       "Binary grading                      12.06      1.00           NaN   \n",
       "Always abstain                       0.00      0.00           0.0   \n",
       "\n",
       "                            overconf_rate  \n",
       "Confidence-aware (t*=0.75)          44.00  \n",
       "Binary grading                      87.94  \n",
       "Always abstain                       0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"gemini-gpqa-baseline-eval.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0915f",
   "metadata": {},
   "source": [
    "## Mistral Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"../inference/outputs/mistral-gpqa.csv\")\n",
    "OUTPUT_PATH = Path(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09884c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1020 rows from mistral-gpqa.csv\n",
      "Thresholds found: [np.float64(0.25), np.float64(0.5), np.float64(0.75), np.float64(0.9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>threshold</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Identify the correct sequence of reagents for ...</td>\n",
       "      <td>['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>There is a C-NOT gate where the condition is t...</td>\n",
       "      <td>['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Two stars are being studied. It has been obser...</td>\n",
       "      <td>['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  threshold                                           question  \\\n",
       "0  203       0.25  Identify the correct sequence of reagents for ...   \n",
       "1  266       0.25  There is a C-NOT gate where the condition is t...   \n",
       "2  152       0.25  Two stars are being studied. It has been obser...   \n",
       "\n",
       "                                             choices answer predicted_answer  \\\n",
       "0  ['1. NaH; CH3CH2Br 2. H2SO4, HNO3 3. Fe-HCl 4....      D                A   \n",
       "1  ['U_{C-NOT}\\\\left|\\\\psi\\\\right\\\\rangle =\\\\alph...      A                B   \n",
       "2  ['ln(2) = [ (T_1 - T_2) / (T1*T2)]', 'ln(2) = ...      A                A   \n",
       "\n",
       "   confidence  \n",
       "0       33.33  \n",
       "1      100.00  \n",
       "2      100.00  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"predicted_answer\"] = df[\"predicted_answer\"].astype(str).str.strip().str.upper()\n",
    "df[\"confidence\"] = round(100*pd.to_numeric(df[\"confidence\"], errors=\"coerce\").fillna(0.0),2)\n",
    "df[\"threshold\"] = pd.to_numeric(df[\"threshold\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH.name}\")\n",
    "print(\"Thresholds found:\", sorted(df[\"threshold\"].unique()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.25: 255 rows\n",
      "t=0.5: 255 rows\n",
      "t=0.75: 255 rows\n",
      "t=0.9: 255 rows\n"
     ]
    }
   ],
   "source": [
    "dfs_by_t = {t: df[df[\"threshold\"] == t].copy() for t in THRESHOLDS}\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    print(f\"t={t}: {len(dfs_by_t[t])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd32b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    df_t = dfs_by_t[t]\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy_at_t\": accuracy_at_threshold(df_t, t),\n",
    "        \"coverage\": coverage(df_t, t),\n",
    "        \"penalty_mean\": penalty_adjusted_mean(df_t, t),\n",
    "        \"overconf_rate\": overconfidence_rate(df_t, t),\n",
    "        \"answered_n\": int((df_t[\"confidence\"] > t).sum()),\n",
    "        \"total_n\": len(df_t)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows).sort_values(\"threshold\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4×4 Evaluation Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>20.78</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-23.08</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>20.39</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-68.30</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>18.43</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-215.64</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>19.61</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-634.21</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               20.78     100.0        -23.08             79\n",
       "0.50               20.39     100.0        -68.30             80\n",
       "0.75               18.43     100.0       -215.64             82\n",
       "0.90               19.61     100.0       -634.21             80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results in: outputs\n"
     ]
    }
   ],
   "source": [
    "eval_table = (\n",
    "    metrics_df[[\"threshold\", \"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]]\n",
    "    .set_index(\"threshold\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(\"4×4 Evaluation Table:\")\n",
    "display(eval_table)\n",
    "\n",
    "eval_table.to_csv(OUTPUT_PATH / \"mistral-gpqa-metric-eval.csv\")\n",
    "\n",
    "print(f\"Saved results in: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "80d715ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG — eligible rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>20.78</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-23.08</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>20.39</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-68.30</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>18.43</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-215.64</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>19.61</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-634.21</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "threshold                                                      \n",
       "0.25               20.78     100.0        -23.08             79\n",
       "0.50               20.39     100.0        -68.30             80\n",
       "0.75               18.43     100.0       -215.64             82\n",
       "0.90               19.61     100.0       -634.21             80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected t* = 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy_at_t     20.78\n",
       "coverage         100.00\n",
       "penalty_mean     -23.08\n",
       "overconf_rate     79.00\n",
       "Name: 0.25, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage_floor = 0.3\n",
    "\n",
    "eligible = eval_table[eval_table[\"coverage\"] >= coverage_floor]\n",
    "print(\"DEBUG — eligible rows:\")\n",
    "display(eligible)\n",
    "\n",
    "best_row = eligible.loc[eligible[\"accuracy_at_t\"].idxmax()]\n",
    "t_star = best_row.name\n",
    "\n",
    "print(f\"Selected t* = {t_star}\")\n",
    "display(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcea55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary-grading baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>19.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Binary           19.8       1.0           NaN           80.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always-abstain baseline:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abstain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy_at_t  coverage  penalty_mean  overconf_rate\n",
       "Abstain            0.0       0.0           0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "binary_acc = np.mean(df[\"predicted_answer\"] == df[\"answer\"])\n",
    "\n",
    "wrong_rate = 1 - binary_acc\n",
    "\n",
    "binary_row = {\n",
    "    \"accuracy_at_t\": round(100*binary_acc,2),\n",
    "    \"coverage\": 1.0,\n",
    "    \"penalty_mean\": np.nan,\n",
    "    \"overconf_rate\": round(100*wrong_rate,2),\n",
    "}\n",
    "\n",
    "abstain_row = {\n",
    "    \"accuracy_at_t\": 0.0,\n",
    "    \"coverage\": 0.0,\n",
    "    \"penalty_mean\": 0.0,\n",
    "    \"overconf_rate\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"Binary-grading baseline:\")\n",
    "display(pd.DataFrame([binary_row], index=[\"Binary\"]))\n",
    "print(\"Always-abstain baseline:\")\n",
    "display(pd.DataFrame([abstain_row], index=[\"Abstain\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17948b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3x4 Headline Evaluation Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_at_t</th>\n",
       "      <th>coverage</th>\n",
       "      <th>penalty_mean</th>\n",
       "      <th>overconf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Confidence-aware (t*=0.25)</th>\n",
       "      <td>20.78</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-23.08</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binary grading</th>\n",
       "      <td>19.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Always abstain</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy_at_t  coverage  penalty_mean  \\\n",
       "Confidence-aware (t*=0.25)          20.78     100.0        -23.08   \n",
       "Binary grading                      19.80       1.0           NaN   \n",
       "Always abstain                       0.00       0.0          0.00   \n",
       "\n",
       "                            overconf_rate  \n",
       "Confidence-aware (t*=0.25)           79.0  \n",
       "Binary grading                       80.2  \n",
       "Always abstain                        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline_df = pd.DataFrame([\n",
    "    best_row[[\"accuracy_at_t\", \"coverage\", \"penalty_mean\", \"overconf_rate\"]],\n",
    "    pd.Series(binary_row),\n",
    "    pd.Series(abstain_row)\n",
    "], index=[f\"Confidence-aware (t*={t_star})\", \"Binary grading\", \"Always abstain\"])\n",
    "\n",
    "print(\"=== 3x4 Headline Evaluation Table ===\")\n",
    "display(headline_df)\n",
    "headline_df.to_csv(OUTPUT_PATH / \"mistral-gpqa-baseline-eval.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
